{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SETTING UP BACKGROUND VARIABLES AND THE DATASETS!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import sys\n",
    "assert sys.version_info.major == 3 and sys.version_info.minor == 11\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, \n",
    "                          TrainingArguments, Trainer, DataCollatorWithPadding, TrainingArguments)\n",
    "from datasets import Dataset, load_dataset, load_metric\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "# from sklearn.model_selection import StratifiedKFold  ###KFolds are not utilized in final model, but they were explored and can be explored in the future.\n",
    "# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "# Load all needed datasets\n",
    "\n",
    "dataset = load_dataset('csv', data_files=r'train\\track_a\\eng.csv')\n",
    "\n",
    "dev_dataset = load_dataset('csv', data_files=r'dev\\track_a\\eng_a.csv')\n",
    "\n",
    "helinski_dataset_raw = load_dataset('csv', data_files=r'xed_fixed.csv')\n",
    "\n",
    "# class_weights = torch.tensor([1.8, 0.7, 1.2, 0.9, 0.9])\n",
    "\n",
    "# loss_fn = CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "#List of classeese and give an \"id\" for each class (0 - 4)\n",
    "\n",
    "classes = [\"Anger\", \"Fear\", \"Joy\", \"Sadness\", \"Surprise\"]\n",
    "class2id = {class_:id for id, class_ in enumerate(classes)}\n",
    "id2class = {id:class_ for class_, id in class2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thato\\miniconda3\\envs\\semeval1\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    " \n",
    "model_path = 'microsoft/deberta-v3-small'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**READ DATA FROM DATASET AND TOKENIZE IT!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331e6fa248664d23a793b6aa56f8a9f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2629 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93465cc5278b43c3bfe36fda2246db8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/139 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5544e7048a4415994728bae8c9a6088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93e4d76295d49ca8ac713b7806d6bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12243 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Load an array for each pair of text/label for each dataset.\n",
    "\n",
    "examples = []\n",
    "y_true = []\n",
    "dev_examples = []\n",
    "dev_y_true = []\n",
    "h_examples = []\n",
    "h_y_true = []\n",
    "num_folds = 5\n",
    "\n",
    "for example in dataset['train']:\n",
    "  examples.append(example['text'])\n",
    "  y_true.append([float(example['Anger']), float(example['Fear']), float(example['Joy']), float(example['Sadness']), float(example['Surprise'])])\n",
    "\n",
    "for example in dev_dataset['train']: #Dev set does not have y-labels.\n",
    "  dev_examples.append(example['text'])\n",
    "  # dev_y_true.append([float(example['Anger']), float(example['Fear']), float(example['Joy']), float(example['Sadness']), float(example['Surprise'])])\n",
    "\n",
    "for example in helinski_dataset_raw['train']:\n",
    "  h_examples.append(example['Sentence'])\n",
    "  h_y_true.append([float(example['Anger']), float(example['Fear']), float(example['Joy']), float(example['Sadness']), float(example['Surprise'])])\n",
    "\n",
    "# make training and validation sets through the training dataset\n",
    "examples_train, examples_test, labels_train, labels_test = train_test_split(examples, y_true, test_size=0.05, random_state=42) #95% of the dataset is training, 5% for eval\n",
    "\n",
    "# print(examples_train)\n",
    "# print(examples_test)\n",
    "\n",
    "#Tokenize each dataset\n",
    "\n",
    "train_dataset = Dataset.from_dict( {\"text\": examples_train, \"label\": labels_train} )\n",
    "test_dataset = Dataset.from_dict( {\"text\": examples_test, \"label\": labels_test} )\n",
    "helinski_dataset = Dataset.from_dict( {\"text\": h_examples, \"label\": h_y_true} )\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "dev_dataset = Dataset.from_dict( {\"text\": dev_examples} )\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_traintest = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_dev = dev_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_helinski = helinski_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Miniature version of dataset to test smaller chunks of data\n",
    "percent_used = 0.6\n",
    "\n",
    "examples_in_train = round(percent_used * len(tokenized_train))\n",
    "examples_in_traintest = round(percent_used * len(tokenized_traintest))\n",
    "\n",
    "mini_tokenized_train = tokenized_train.select(range(examples_in_train)) # make so works with percent_used\n",
    "mini_tokenized_traintest = tokenized_traintest.select(range(examples_in_traintest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SET UP VARIABLES AND FUNCTIONS FOR RESULTS LOG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "# Code to print the results of the test.  \n",
    "\n",
    "# training!\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, problem_type=\"multi_label_classification\", num_labels=5)\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", eval_strategy=\"epoch\")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "\n",
    "def sigmoid(x):\n",
    "   return 1/(1 + np.exp(-x))\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "   predictions, labels = eval_pred\n",
    "   predictions = sigmoid(predictions)\n",
    "   predictions = (predictions > 0.5).astype(int).reshape(-1)\n",
    "   return clf_metrics.compute(predictions=predictions, references=labels.astype(int).reshape(-1))\n",
    "\n",
    "\n",
    "#references=labels.astype(int).reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SET UP MODEL AND TRAIN IT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "\n",
    "   model_path, num_labels=len(classes),\n",
    "           id2label=id2class, label2id=class2id,\n",
    "                       problem_type = \"multi_label_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thato\\miniconda3\\envs\\semeval1\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e2bebff2e34129a4dbcc72b56de1e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b161be90a9354a22bdcafa69c0cbe220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4998610019683838, 'eval_accuracy': 0.7566265060240964, 'eval_f1': 0.5511111111111111, 'eval_precision': 0.6526315789473685, 'eval_recall': 0.47692307692307695, 'eval_runtime': 1.894, 'eval_samples_per_second': 43.822, 'eval_steps_per_second': 5.808, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e88354ee6504a3c8a33d91fa7938cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.468421995639801, 'eval_accuracy': 0.7855421686746988, 'eval_f1': 0.611353711790393, 'eval_precision': 0.7070707070707071, 'eval_recall': 0.5384615384615384, 'eval_runtime': 2.2325, 'eval_samples_per_second': 37.177, 'eval_steps_per_second': 4.927, 'epoch': 2.0}\n",
      "{'loss': 0.4892, 'grad_norm': 1.6179118156433105, 'learning_rate': 3.1649831649831652e-06, 'epoch': 2.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d2a10a17b947c1bb2df94d00b9559c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45839911699295044, 'eval_accuracy': 0.7855421686746988, 'eval_f1': 0.6147186147186147, 'eval_precision': 0.7029702970297029, 'eval_recall': 0.5461538461538461, 'eval_runtime': 2.1552, 'eval_samples_per_second': 38.512, 'eval_steps_per_second': 5.104, 'epoch': 3.0}\n",
      "{'train_runtime': 940.4943, 'train_samples_per_second': 5.03, 'train_steps_per_second': 0.632, 'train_loss': 0.4732129389188105, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=594, training_loss=0.4732129389188105, metrics={'train_runtime': 940.4943, 'train_samples_per_second': 5.03, 'train_steps_per_second': 0.632, 'total_flos': 51171127674744.0, 'train_loss': 0.4732129389188105, 'epoch': 3.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(num_folds):\n",
    "\n",
    "#Best model for Deberta: batch_size = 8, learning_rate = 2e-5\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "   output_dir=\"my_awesome_model\",\n",
    "   per_device_train_batch_size = 8, \n",
    "   learning_rate= 2e-5,\n",
    "   # per_device_eval_batch_size=3,\n",
    "   num_train_epochs=3,\n",
    "   evaluation_strategy=\"epoch\",\n",
    "   save_strategy=\"epoch\",\n",
    "   load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=mini_tokenized_train,\n",
    "   eval_dataset=mini_tokenized_traintest,\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEST THE MODEL ADN RUN PRINT RESULTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2efa1951ca48b38c836d337bc2e5f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS LOG:\n",
      "F1: 0.6753795196029225\n",
      "0.3\n",
      "THRESH =  0.35\n",
      "0.6389524831050389\n",
      "0.6547085201793722\n",
      "0.5568304325475507\n",
      "==============\n",
      "THRESH =  0.4\n",
      "0.6427443178885135\n",
      "0.6650943396226415\n",
      "0.5462273076843134\n",
      "==============\n",
      "THRESH =  0.45\n",
      "0.6243502185791249\n",
      "0.6551724137931034\n",
      "0.5035026195837675\n",
      "==============\n",
      "THRESH =  0.5\n",
      "0.6130127818877478\n",
      "0.6478149100257069\n",
      "0.4924848500119688\n",
      "==============\n"
     ]
    }
   ],
   "source": [
    "TESTING_SET = tokenized_traintest #adjust testing set as needed.\n",
    "\n",
    "predictions = trainer.predict(TESTING_SET)\n",
    "# print(predictions)\n",
    "\n",
    "# Precision and recall (macro-average across labels)\n",
    "# precision_macro = precision_score(predictions['label_ids'].tolist(), y_true, average='macro')\n",
    "# recall_macro = recall_score(predictions['label_ids'].tolist(), y_true, average='macro')\n",
    "\n",
    "# # Precision and recall (micro-average across all samples and labels)\n",
    "# precision_micro = precision_score(predictions, y_true, average='micro')\n",
    "# recall_micro = recall_score(predictions, y_true, average='micro')\n",
    "\n",
    "probs = sigmoid(torch.from_numpy(predictions.predictions))\n",
    "# print(\"PROBS: \", probs)\n",
    "# print(\"LABELS: \", torch.tensor(tokenized_test['label'])) # trues\n",
    "print(f\"RESULTS LOG:\")\n",
    "nums = np.round(np.linspace(.3, .7, 40), 2)\n",
    "final_nums = np.append(nums, 0.5)\n",
    "\n",
    "best_thresh = 0\n",
    "best_f1 = 0\n",
    "for curr_thresh in final_nums:\n",
    "# binarize predictions\n",
    "   binary_predictions = (probs >= curr_thresh).long()\n",
    "   # print(\"PREDS: \", binary_predictions)\n",
    "   curr_f1 = f1_score(y_true=TESTING_SET['label'], y_pred=binary_predictions, average='weighted')\n",
    "   if curr_f1 > best_f1:\n",
    "      best_f1 = curr_f1\n",
    "      best_thresh = curr_thresh\n",
    "# print(\"THRESH = \", curr_thresh, \" F1 = \", curr_f1)\n",
    "print(f\"F1: {best_f1}\")\n",
    "print(best_thresh)\n",
    "\n",
    "for thresh in [0.35, 0.4, 0.45, 0.5]:\n",
    "# binarize predictions\n",
    "   binary_predictions = (probs >= thresh).long()\n",
    "   print(\"THRESH = \", thresh)\n",
    "   # print(\"PREDS: \", binary_predictions)\n",
    "   print(f1_score(y_true=TESTING_SET['label'], y_pred=binary_predictions, average='weighted'))\n",
    "   print(f1_score(y_true=TESTING_SET['label'], y_pred=binary_predictions, average='micro'))\n",
    "   print(f1_score(y_true=TESTING_SET['label'], y_pred=binary_predictions, average='macro'))\n",
    "   print(\"==============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b3167b606b49b3a985c98f660d45d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBS:  tensor([[0.0944, 0.8349, 0.0475, 0.2699, 0.4449],\n",
      "        [0.0632, 0.9215, 0.0295, 0.3606, 0.2794],\n",
      "        [0.0336, 0.3242, 0.2733, 0.0616, 0.3499],\n",
      "        [0.0336, 0.3818, 0.3117, 0.2862, 0.0584],\n",
      "        [0.0304, 0.1225, 0.5641, 0.0790, 0.1430],\n",
      "        [0.0609, 0.8911, 0.0586, 0.6105, 0.0725],\n",
      "        [0.4586, 0.8376, 0.0749, 0.3554, 0.7016],\n",
      "        [0.0315, 0.4097, 0.2843, 0.3060, 0.0656],\n",
      "        [0.0200, 0.4959, 0.2000, 0.1125, 0.0816],\n",
      "        [0.0614, 0.9077, 0.0498, 0.5617, 0.0798],\n",
      "        [0.0398, 0.1279, 0.6201, 0.0616, 0.2791],\n",
      "        [0.0858, 0.9210, 0.0448, 0.6360, 0.0831],\n",
      "        [0.2529, 0.7311, 0.0925, 0.2191, 0.7777],\n",
      "        [0.2992, 0.8973, 0.0487, 0.3567, 0.6585],\n",
      "        [0.0538, 0.0686, 0.7802, 0.1050, 0.1612],\n",
      "        [0.0282, 0.7867, 0.0585, 0.1977, 0.1638],\n",
      "        [0.3646, 0.8330, 0.0630, 0.5522, 0.4754],\n",
      "        [0.0306, 0.7037, 0.0946, 0.0866, 0.2853],\n",
      "        [0.1918, 0.8861, 0.0480, 0.2545, 0.6423],\n",
      "        [0.0458, 0.8345, 0.0584, 0.3750, 0.1571],\n",
      "        [0.0593, 0.0803, 0.7843, 0.1002, 0.2601],\n",
      "        [0.0815, 0.9364, 0.0368, 0.5645, 0.1085],\n",
      "        [0.4754, 0.8297, 0.0802, 0.3912, 0.7243],\n",
      "        [0.4299, 0.8407, 0.0819, 0.3419, 0.7594],\n",
      "        [0.0863, 0.6306, 0.0974, 0.1939, 0.4230],\n",
      "        [0.0752, 0.2728, 0.3147, 0.0698, 0.5254],\n",
      "        [0.1476, 0.8936, 0.0410, 0.3018, 0.6124],\n",
      "        [0.0618, 0.0715, 0.7560, 0.0687, 0.3308],\n",
      "        [0.0503, 0.1173, 0.6566, 0.1478, 0.1290],\n",
      "        [0.0346, 0.6786, 0.1015, 0.0956, 0.3400],\n",
      "        [0.0303, 0.7849, 0.0794, 0.2685, 0.0750],\n",
      "        [0.0354, 0.4620, 0.2071, 0.0645, 0.2915],\n",
      "        [0.4764, 0.7948, 0.0982, 0.3868, 0.7496],\n",
      "        [0.3758, 0.9092, 0.0519, 0.7080, 0.3591],\n",
      "        [0.0410, 0.7418, 0.0812, 0.0999, 0.3517],\n",
      "        [0.0303, 0.7838, 0.0664, 0.1903, 0.1345],\n",
      "        [0.0526, 0.8216, 0.1008, 0.5322, 0.0515],\n",
      "        [0.1135, 0.9221, 0.0561, 0.7290, 0.0757],\n",
      "        [0.0835, 0.0802, 0.8318, 0.1260, 0.2168],\n",
      "        [0.0317, 0.1647, 0.4849, 0.1246, 0.1056],\n",
      "        [0.0304, 0.2667, 0.4623, 0.1842, 0.0679],\n",
      "        [0.0239, 0.3166, 0.2410, 0.0630, 0.2373],\n",
      "        [0.2918, 0.9438, 0.0372, 0.6360, 0.2923],\n",
      "        [0.0190, 0.2719, 0.3434, 0.0627, 0.1304],\n",
      "        [0.2345, 0.9326, 0.0326, 0.5574, 0.4072],\n",
      "        [0.0568, 0.9199, 0.0334, 0.4645, 0.1464],\n",
      "        [0.0339, 0.1244, 0.5611, 0.1129, 0.1008],\n",
      "        [0.0922, 0.7851, 0.0654, 0.1432, 0.6628],\n",
      "        [0.0757, 0.9285, 0.0415, 0.5680, 0.0903],\n",
      "        [0.0278, 0.7911, 0.0644, 0.1583, 0.1462],\n",
      "        [0.0928, 0.9169, 0.0488, 0.6913, 0.0874],\n",
      "        [0.3123, 0.9348, 0.0406, 0.5210, 0.4554],\n",
      "        [0.0679, 0.4503, 0.1769, 0.2067, 0.2604],\n",
      "        [0.1141, 0.6080, 0.1193, 0.2543, 0.4836],\n",
      "        [0.0409, 0.1752, 0.4429, 0.0518, 0.4047],\n",
      "        [0.1455, 0.9378, 0.0431, 0.6998, 0.1062],\n",
      "        [0.0428, 0.4393, 0.1955, 0.1720, 0.2290],\n",
      "        [0.0442, 0.0968, 0.6778, 0.0583, 0.2481],\n",
      "        [0.3352, 0.6810, 0.1216, 0.2459, 0.7401],\n",
      "        [0.0388, 0.5206, 0.2512, 0.4027, 0.0552],\n",
      "        [0.0302, 0.1434, 0.6071, 0.0967, 0.0959],\n",
      "        [0.1990, 0.8949, 0.0437, 0.2793, 0.6522],\n",
      "        [0.0213, 0.4647, 0.1751, 0.0696, 0.1630],\n",
      "        [0.0512, 0.8799, 0.0432, 0.3914, 0.1490],\n",
      "        [0.0287, 0.5173, 0.2443, 0.2657, 0.0554],\n",
      "        [0.1033, 0.9268, 0.0473, 0.6909, 0.0851],\n",
      "        [0.0417, 0.8940, 0.0469, 0.3882, 0.0865],\n",
      "        [0.2036, 0.6305, 0.1398, 0.1343, 0.7786],\n",
      "        [0.0609, 0.8722, 0.0696, 0.6196, 0.0650],\n",
      "        [0.0544, 0.9097, 0.0500, 0.5200, 0.0766],\n",
      "        [0.0738, 0.0625, 0.8090, 0.1079, 0.1900],\n",
      "        [0.0440, 0.1018, 0.7118, 0.0686, 0.2525],\n",
      "        [0.2529, 0.8060, 0.0700, 0.2100, 0.7472],\n",
      "        [0.0537, 0.1673, 0.4484, 0.0601, 0.4501],\n",
      "        [0.1452, 0.9124, 0.0450, 0.7532, 0.1443],\n",
      "        [0.0849, 0.2131, 0.4224, 0.0695, 0.5595],\n",
      "        [0.0515, 0.1037, 0.6974, 0.1486, 0.1056],\n",
      "        [0.1775, 0.6951, 0.1010, 0.1569, 0.7677],\n",
      "        [0.0552, 0.1697, 0.4754, 0.0562, 0.4635],\n",
      "        [0.1157, 0.9261, 0.0499, 0.7076, 0.0846],\n",
      "        [0.0676, 0.8930, 0.0662, 0.6081, 0.0585],\n",
      "        [0.1433, 0.9506, 0.0332, 0.6312, 0.1502],\n",
      "        [0.0445, 0.7818, 0.0756, 0.4342, 0.1137],\n",
      "        [0.0736, 0.2809, 0.2883, 0.0677, 0.6188],\n",
      "        [0.1815, 0.9332, 0.0366, 0.7369, 0.1669],\n",
      "        [0.0625, 0.0925, 0.7480, 0.0713, 0.2913],\n",
      "        [0.1039, 0.8641, 0.0457, 0.5921, 0.2423],\n",
      "        [0.1860, 0.7060, 0.1070, 0.3755, 0.4609],\n",
      "        [0.0482, 0.8793, 0.0612, 0.5439, 0.0728],\n",
      "        [0.1269, 0.9461, 0.0366, 0.6077, 0.1215],\n",
      "        [0.0739, 0.6867, 0.0818, 0.1138, 0.6047],\n",
      "        [0.1290, 0.9067, 0.0330, 0.3359, 0.5211],\n",
      "        [0.3002, 0.9392, 0.0372, 0.5993, 0.4032],\n",
      "        [0.2036, 0.9460, 0.0304, 0.6087, 0.2824],\n",
      "        [0.0340, 0.8016, 0.0608, 0.3701, 0.1104],\n",
      "        [0.4376, 0.7853, 0.0963, 0.2975, 0.7698],\n",
      "        [0.0550, 0.9198, 0.0308, 0.4144, 0.1871],\n",
      "        [0.0804, 0.9178, 0.0521, 0.6059, 0.0723],\n",
      "        [0.0272, 0.5772, 0.1262, 0.0728, 0.2802],\n",
      "        [0.0616, 0.8744, 0.0393, 0.1881, 0.4222],\n",
      "        [0.0375, 0.5970, 0.1334, 0.0673, 0.3813],\n",
      "        [0.0232, 0.5551, 0.1808, 0.1946, 0.0628],\n",
      "        [0.2840, 0.8074, 0.0755, 0.2637, 0.7431],\n",
      "        [0.0921, 0.9268, 0.0284, 0.3565, 0.3738],\n",
      "        [0.0202, 0.5962, 0.1355, 0.1606, 0.0924],\n",
      "        [0.0333, 0.2941, 0.3289, 0.0486, 0.3649],\n",
      "        [0.0804, 0.8261, 0.0910, 0.7038, 0.0693],\n",
      "        [0.0236, 0.6035, 0.1272, 0.2025, 0.0805],\n",
      "        [0.0611, 0.3935, 0.3289, 0.3906, 0.0903],\n",
      "        [0.4041, 0.9033, 0.0502, 0.6457, 0.4200],\n",
      "        [0.0212, 0.5658, 0.1409, 0.0788, 0.1595],\n",
      "        [0.1813, 0.7739, 0.0711, 0.2117, 0.7186],\n",
      "        [0.0739, 0.6617, 0.1086, 0.0874, 0.6499],\n",
      "        [0.0675, 0.9057, 0.0499, 0.5761, 0.0733],\n",
      "        [0.0279, 0.2470, 0.4241, 0.1843, 0.0695],\n",
      "        [0.1929, 0.8143, 0.0618, 0.2076, 0.7691]])\n",
      "tensor([[0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [1, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [1, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [1, 1, 0, 1, 1],\n",
      "        [1, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [1, 1, 0, 1, 1],\n",
      "        [1, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 0, 1, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 0, 1, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 1],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 0, 1, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [1, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [1, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Code to generate a .csv for the dev set to submit to SemEval competition.\n",
    "\n",
    "predictions = trainer.predict(tokenized_dev) # logits\n",
    "probs = torch.sigmoid(torch.from_numpy(predictions.predictions)) # percentage probabilities\n",
    "print(\"PROBS: \", probs)\n",
    "binary_predictions = (probs >= 0.35).long()\n",
    "print(binary_predictions)\n",
    "\n",
    "# Convert tensors to integers\n",
    "binary_predictions_list = binary_predictions.tolist()\n",
    "\n",
    "\n",
    "ids = []\n",
    "for i in range(0, len(binary_predictions_list)):\n",
    "  ids.append(\"text\" + str(i))\n",
    "\n",
    "data = {\n",
    "    \"id\": ids,\n",
    "    \"Anger\": [pred[0] for pred in binary_predictions_list],\n",
    "    \"Fear\": [pred[1] for pred in binary_predictions_list],\n",
    "    \"Joy\": [pred[2] for pred in binary_predictions_list],\n",
    "    \"Sadness\": [pred[3] for pred in binary_predictions_list],\n",
    "    \"Surprise\": [pred[4] for pred in binary_predictions_list],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"pred_eng_a.csv\", index=False) # drop the index column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISCONTINUIED GRID SEARCH CODE\n",
    "\n",
    "# possible_learn_rate = [2e-4, 2e-5, 2e-6]\n",
    "# possible_batch_size = [8, 16, 32]\n",
    "\n",
    "\n",
    "# for learn_r in possible_learn_rate:\n",
    "#    for batch_s in possible_batch_size:\n",
    "#       training_args = TrainingArguments(\n",
    "#          output_dir=\"my_awesome_model\",\n",
    "#          per_device_train_batch_size = batch_s,\n",
    "#          learning_rate= learn_r,\n",
    "#          # per_device_train_batch_size=3,\n",
    "#          # per_device_eval_batch_size=3,\n",
    "#          num_train_epochs=3,\n",
    "#          weight_decay=0.01,\n",
    "#          evaluation_strategy=\"epoch\",\n",
    "#          save_strategy=\"epoch\",\n",
    "#          load_best_model_at_end=True,\n",
    "#       )\n",
    "\n",
    "#       trainer = Trainer(\n",
    "\n",
    "#          model=model,\n",
    "#          args=training_args,\n",
    "#          train_dataset=tokenized_train,\n",
    "#          eval_dataset=tokenized_test      ,\n",
    "#          tokenizer=tokenizer,\n",
    "#          data_collator=data_collator,\n",
    "#          compute_metrics=compute_metrics,\n",
    "#          # mini_batch_sizee = b_s\n",
    "#       )\n",
    "\n",
    "#       trainer.train()\n",
    "#       predictions = trainer.predict(tokenized_test)\n",
    "#       probs = sigmoid(torch.from_numpy(predictions.predictions))\n",
    "#       # print(\"PROBS: \", probs)\n",
    "#       # print(\"LABELS: \", torch.tensor(tokenized_test['label'])) # trues\n",
    "#       print(f\"LOG: Learn: {learn_r} Batch: {batch_s}\")\n",
    "#       for thresh in [0.35, 0.4, 0.45, 0.5]:\n",
    "#       # binarize predictions\n",
    "#          binary_predictions = (probs >= thresh).long()\n",
    "#          print(\"THRESH = \", thresh)\n",
    "#          # print(\"PREDS: \", binary_predictions)\n",
    "\n",
    "#          print(f1_score(y_true=tokenized_test['label'], y_pred=binary_predictions, average='weighted'))\n",
    "#          print(f1_score(y_true=tokenized_test['label'], y_pred=binary_predictions, average='micro'))\n",
    "#          print(f1_score(y_true=tokenized_test['label'], y_pred=binary_predictions, average='macro'))\n",
    "#          print(\"==============\")\n",
    "#       nums = np.round(np.linspace(.3, .7, 40), 2)\n",
    "#       final_nums = np.append(nums, 0.5)\n",
    "\n",
    "#       best_thresh = 0\n",
    "#       best_f1 = 0\n",
    "#       for curr_thresh in final_nums:\n",
    "#       # binarize predictions\n",
    "#          binary_predictions = (probs >= curr_thresh).long()\n",
    "         \n",
    "#          # print(\"PREDS: \", binary_predictions)\n",
    "\n",
    "#          curr_f1 = f1_score(y_true=tokenized_test['label'], y_pred=binary_predictions, average='weighted')\n",
    "#          if curr_f1 > best_f1:\n",
    "#             best_f1 = curr_f1\n",
    "#             best_thresh = curr_thresh\n",
    "#       # print(\"THRESH = \", curr_thresh, \" F1 = \", curr_f1)\n",
    "#       print(f\"F1: {best_f1}\")\n",
    "#       print(best_thresh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semeval1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
