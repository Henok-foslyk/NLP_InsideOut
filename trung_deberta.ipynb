{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SETTING UP BACKGROUND VARIABLES AND THE DATASETS!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import sys\n",
    "assert sys.version_info.major == 3 and sys.version_info.minor == 11\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, \n",
    "                          TrainingArguments, Trainer, DataCollatorWithPadding, TrainingArguments)\n",
    "from datasets import Dataset, load_dataset, load_metric\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "# from sklearn.model_selection import StratifiedKFold  ###KFolds are not utilized in final model, but they were explored and can be explored in the future.\n",
    "# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "# Load all needed datasets\n",
    "\n",
    "dataset = load_dataset('csv', data_files=r'train\\track_a\\eng.csv')\n",
    "\n",
    "dev_dataset = load_dataset('csv', data_files=r'dev\\track_a\\eng_a.csv')\n",
    "\n",
    "helinski_dataset_raw = load_dataset('csv', data_files=r'xed_fixed.csv')\n",
    "\n",
    "# class_weights = torch.tensor([1.8, 0.7, 1.2, 0.9, 0.9])\n",
    "\n",
    "# loss_fn = CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "#List of classeese and give an \"id\" for each class (0 - 4)\n",
    "\n",
    "classes = [\"Anger\", \"Fear\", \"Joy\", \"Sadness\", \"Surprise\"]\n",
    "class2id = {class_:id for id, class_ in enumerate(classes)}\n",
    "id2class = {id:class_ for class_, id in class2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thato\\miniconda3\\envs\\semeval1\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    " \n",
    "model_path = 'microsoft/deberta-v3-small'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**READ DATA FROM DATASET AND TOKENIZE IT!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f809bb237f4b55bbb7c80fe701cd3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2629 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ba346419a442e6ba9c374f1d637548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/139 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b589d4cdbaf46c3bec350b4a9b6141c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbfb66dd45d54dff9efbdf530875ab28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12243 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Load an array for each pair of text/label for each dataset.\n",
    "\n",
    "examples = []\n",
    "y_true = []\n",
    "dev_examples = []\n",
    "dev_y_true = []\n",
    "h_examples = []\n",
    "h_y_true = []\n",
    "num_folds = 5\n",
    "\n",
    "for example in dataset['train']:\n",
    "  examples.append(example['text'])\n",
    "  y_true.append([float(example['Anger']), float(example['Fear']), float(example['Joy']), float(example['Sadness']), float(example['Surprise'])])\n",
    "\n",
    "for example in dev_dataset['train']: #Dev set does not have y-labels.\n",
    "  dev_examples.append(example['text'])\n",
    "  # dev_y_true.append([float(example['Anger']), float(example['Fear']), float(example['Joy']), float(example['Sadness']), float(example['Surprise'])])\n",
    "\n",
    "for example in helinski_dataset_raw['train']:\n",
    "  h_examples.append(example['Sentence'])\n",
    "  h_y_true.append([float(example['Anger']), float(example['Fear']), float(example['Joy']), float(example['Sadness']), float(example['Surprise'])])\n",
    "\n",
    "# make training and validation sets through the training dataset\n",
    "examples_train, examples_test, labels_train, labels_test = train_test_split(examples, y_true, test_size=0.05, random_state=42) #95% of the dataset is training, 5% for eval\n",
    "\n",
    "# print(examples_train)\n",
    "# print(examples_test)\n",
    "\n",
    "#Tokenize each dataset\n",
    "\n",
    "train_dataset = Dataset.from_dict( {\"text\": examples_train, \"label\": labels_train} )\n",
    "test_dataset = Dataset.from_dict( {\"text\": examples_test, \"label\": labels_test} )\n",
    "helinski_dataset = Dataset.from_dict( {\"text\": h_examples, \"label\": h_y_true} )\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "dev_dataset = Dataset.from_dict( {\"text\": dev_examples} )\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_traintest = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_dev = dev_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_helinski = helinski_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Miniature version of dataset to test smaller chunks of data\n",
    "percent_used = 0.6\n",
    "\n",
    "examples_in_train = round(percent_used * len(tokenized_train))\n",
    "examples_in_traintest = round(percent_used * len(tokenized_traintest))\n",
    "\n",
    "mini_tokenized_train = tokenized_train.select(range(examples_in_train)) # make so works with percent_used\n",
    "mini_tokenized_traintest = tokenized_traintest.select(range(examples_in_traintest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SET UP VARIABLES AND FUNCTIONS FOR RESULTS LOG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "# Code to print the results of the test.  \n",
    "\n",
    "# training!\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, problem_type=\"multi_label_classification\", num_labels=5)\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", eval_strategy=\"epoch\")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "\n",
    "def sigmoid(x):\n",
    "   return 1/(1 + np.exp(-x))\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "   predictions, labels = eval_pred\n",
    "   predictions = sigmoid(predictions)\n",
    "   predictions = (predictions > 0.5).astype(int).reshape(-1)\n",
    "   return clf_metrics.compute(predictions=predictions, references=labels.astype(int).reshape(-1))\n",
    "\n",
    "\n",
    "#references=labels.astype(int).reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SET UP MODEL AND TRAIN IT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "\n",
    "   model_path, num_labels=len(classes),\n",
    "           id2label=id2class, label2id=class2id,\n",
    "                       problem_type = \"multi_label_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thato\\miniconda3\\envs\\semeval1\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c508deea4a3d4854809c4ecba2e19a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4decf8354c22495299b6e9dcfe323f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.48990315198898315, 'eval_accuracy': 0.7421686746987952, 'eval_f1': 0.5327510917030568, 'eval_precision': 0.6161616161616161, 'eval_recall': 0.46923076923076923, 'eval_runtime': 2.1037, 'eval_samples_per_second': 39.454, 'eval_steps_per_second': 5.229, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b9539d58f740efb27f7f4e41cf5b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.46349036693573, 'eval_accuracy': 0.7807228915662651, 'eval_f1': 0.6285714285714286, 'eval_precision': 0.6695652173913044, 'eval_recall': 0.5923076923076923, 'eval_runtime': 1.8907, 'eval_samples_per_second': 43.898, 'eval_steps_per_second': 5.818, 'epoch': 2.0}\n",
      "{'loss': 0.4761, 'grad_norm': 1.7204116582870483, 'learning_rate': 3.1649831649831652e-06, 'epoch': 2.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ae769968db4ddcad05b2c3092e0c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4551863968372345, 'eval_accuracy': 0.7855421686746988, 'eval_f1': 0.6307053941908713, 'eval_precision': 0.6846846846846847, 'eval_recall': 0.5846153846153846, 'eval_runtime': 2.0627, 'eval_samples_per_second': 40.238, 'eval_steps_per_second': 5.333, 'epoch': 3.0}\n",
      "{'train_runtime': 959.6089, 'train_samples_per_second': 4.93, 'train_steps_per_second': 0.619, 'train_loss': 0.4592141816110322, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=594, training_loss=0.4592141816110322, metrics={'train_runtime': 959.6089, 'train_samples_per_second': 4.93, 'train_steps_per_second': 0.619, 'total_flos': 51171127674744.0, 'train_loss': 0.4592141816110322, 'epoch': 3.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(num_folds):\n",
    "\n",
    "#Best model for Deberta: batch_size = 8, learning_rate = 2e-5\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "   output_dir=\"my_awesome_model\",\n",
    "   per_device_train_batch_size = 8, \n",
    "   learning_rate= 2e-5,\n",
    "   # per_device_eval_batch_size=3,\n",
    "   num_train_epochs=3,\n",
    "   evaluation_strategy=\"epoch\",\n",
    "   save_strategy=\"epoch\",\n",
    "   load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=mini_tokenized_train,\n",
    "   eval_dataset=mini_tokenized_traintest,\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEST THE MODEL ADN RUN PRINT RESULTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3730aa726ff43bca400322937d62f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS LOG:\n",
      "F1: 0.6876758448589435\n",
      "0.31\n",
      "THRESH =  0.35\n",
      "0.673826442175757\n",
      "0.6810344827586207\n",
      "0.6140554861098155\n",
      "==============\n",
      "THRESH =  0.4\n",
      "0.6554094621547428\n",
      "0.6757369614512472\n",
      "0.5573199715870913\n",
      "==============\n",
      "THRESH =  0.45\n",
      "0.6364577159198033\n",
      "0.6666666666666666\n",
      "0.5156916108888934\n",
      "==============\n",
      "THRESH =  0.5\n",
      "0.6239147821006431\n",
      "0.6567164179104478\n",
      "0.5026681253049097\n",
      "==============\n",
      "MACROS: Precision: 0.4808811503339239  Recall: 0.5437038354204574 \n",
      "MICROS: Precision: 0.6197183098591549  Recall: 0.6984126984126984 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thato\\miniconda3\\envs\\semeval1\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "TESTING_SET = tokenized_traintest #adjust testing set as needed.\n",
    "\n",
    "predictions = trainer.predict(TESTING_SET)\n",
    "# print(compute_metrics(predictions.label_ids))\n",
    "# print(predictions)\n",
    "\n",
    "\n",
    "\n",
    "probs = sigmoid(torch.from_numpy(predictions.predictions))\n",
    "# print(\"PROBS: \", probs)\n",
    "# print(\"LABELS: \", torch.tensor(tokenized_test['label'])) # trues\n",
    "print(f\"RESULTS LOG:\")\n",
    "nums = np.round(np.linspace(.3, .7, 40), 2)\n",
    "final_nums = np.append(nums, 0.5)\n",
    "\n",
    "best_thresh = 0\n",
    "best_f1 = 0\n",
    "for curr_thresh in final_nums:\n",
    "# binarize predictions\n",
    "   binary_predictions = (probs >= curr_thresh).long()\n",
    "   # print(\"PREDS: \", binary_predictions)\n",
    "   curr_f1 = f1_score(y_true=TESTING_SET['label'], y_pred=binary_predictions, average='weighted')\n",
    "   if curr_f1 > best_f1:\n",
    "      best_f1 = curr_f1\n",
    "      best_thresh = curr_thresh\n",
    "# print(\"THRESH = \", curr_thresh, \" F1 = \", curr_f1)\n",
    "print(f\"F1: {best_f1}\")\n",
    "print(best_thresh)\n",
    "\n",
    "for thresh in [0.35, 0.4, 0.45, 0.5]:\n",
    "# binarize predictions\n",
    "   binary_predictions = (probs >= thresh).long()\n",
    "   print(\"THRESH = \", thresh)\n",
    "   # print(\"PREDS: \", binary_predictions)\n",
    "   print(f1_score(y_true=TESTING_SET['label'], y_pred=binary_predictions, average='weighted'))\n",
    "   print(f1_score(y_true=TESTING_SET['label'], y_pred=binary_predictions, average='micro'))\n",
    "   print(f1_score(y_true=TESTING_SET['label'], y_pred=binary_predictions, average='macro'))\n",
    "   print(\"==============\")\n",
    "\n",
    "# Precision and recall (macro-average across labels)\n",
    "precision_macro = precision_score(binary_predictions, labels_test, average='macro')\n",
    "recall_macro = recall_score(binary_predictions, labels_test, average='macro')\n",
    "\n",
    "# Precision and recall (micro-average across all samples and labels)\n",
    "precision_micro = precision_score(binary_predictions, labels_test, average='micro')\n",
    "recall_micro = recall_score(binary_predictions, labels_test, average='micro')\n",
    "\n",
    "print(f\"MACROS: Precision: {precision_macro}  Recall: {recall_macro} \")\n",
    "print(f\"MICROS: Precision: {precision_micro}  Recall: {recall_micro} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b3167b606b49b3a985c98f660d45d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBS:  tensor([[0.0944, 0.8349, 0.0475, 0.2699, 0.4449],\n",
      "        [0.0632, 0.9215, 0.0295, 0.3606, 0.2794],\n",
      "        [0.0336, 0.3242, 0.2733, 0.0616, 0.3499],\n",
      "        [0.0336, 0.3818, 0.3117, 0.2862, 0.0584],\n",
      "        [0.0304, 0.1225, 0.5641, 0.0790, 0.1430],\n",
      "        [0.0609, 0.8911, 0.0586, 0.6105, 0.0725],\n",
      "        [0.4586, 0.8376, 0.0749, 0.3554, 0.7016],\n",
      "        [0.0315, 0.4097, 0.2843, 0.3060, 0.0656],\n",
      "        [0.0200, 0.4959, 0.2000, 0.1125, 0.0816],\n",
      "        [0.0614, 0.9077, 0.0498, 0.5617, 0.0798],\n",
      "        [0.0398, 0.1279, 0.6201, 0.0616, 0.2791],\n",
      "        [0.0858, 0.9210, 0.0448, 0.6360, 0.0831],\n",
      "        [0.2529, 0.7311, 0.0925, 0.2191, 0.7777],\n",
      "        [0.2992, 0.8973, 0.0487, 0.3567, 0.6585],\n",
      "        [0.0538, 0.0686, 0.7802, 0.1050, 0.1612],\n",
      "        [0.0282, 0.7867, 0.0585, 0.1977, 0.1638],\n",
      "        [0.3646, 0.8330, 0.0630, 0.5522, 0.4754],\n",
      "        [0.0306, 0.7037, 0.0946, 0.0866, 0.2853],\n",
      "        [0.1918, 0.8861, 0.0480, 0.2545, 0.6423],\n",
      "        [0.0458, 0.8345, 0.0584, 0.3750, 0.1571],\n",
      "        [0.0593, 0.0803, 0.7843, 0.1002, 0.2601],\n",
      "        [0.0815, 0.9364, 0.0368, 0.5645, 0.1085],\n",
      "        [0.4754, 0.8297, 0.0802, 0.3912, 0.7243],\n",
      "        [0.4299, 0.8407, 0.0819, 0.3419, 0.7594],\n",
      "        [0.0863, 0.6306, 0.0974, 0.1939, 0.4230],\n",
      "        [0.0752, 0.2728, 0.3147, 0.0698, 0.5254],\n",
      "        [0.1476, 0.8936, 0.0410, 0.3018, 0.6124],\n",
      "        [0.0618, 0.0715, 0.7560, 0.0687, 0.3308],\n",
      "        [0.0503, 0.1173, 0.6566, 0.1478, 0.1290],\n",
      "        [0.0346, 0.6786, 0.1015, 0.0956, 0.3400],\n",
      "        [0.0303, 0.7849, 0.0794, 0.2685, 0.0750],\n",
      "        [0.0354, 0.4620, 0.2071, 0.0645, 0.2915],\n",
      "        [0.4764, 0.7948, 0.0982, 0.3868, 0.7496],\n",
      "        [0.3758, 0.9092, 0.0519, 0.7080, 0.3591],\n",
      "        [0.0410, 0.7418, 0.0812, 0.0999, 0.3517],\n",
      "        [0.0303, 0.7838, 0.0664, 0.1903, 0.1345],\n",
      "        [0.0526, 0.8216, 0.1008, 0.5322, 0.0515],\n",
      "        [0.1135, 0.9221, 0.0561, 0.7290, 0.0757],\n",
      "        [0.0835, 0.0802, 0.8318, 0.1260, 0.2168],\n",
      "        [0.0317, 0.1647, 0.4849, 0.1246, 0.1056],\n",
      "        [0.0304, 0.2667, 0.4623, 0.1842, 0.0679],\n",
      "        [0.0239, 0.3166, 0.2410, 0.0630, 0.2373],\n",
      "        [0.2918, 0.9438, 0.0372, 0.6360, 0.2923],\n",
      "        [0.0190, 0.2719, 0.3434, 0.0627, 0.1304],\n",
      "        [0.2345, 0.9326, 0.0326, 0.5574, 0.4072],\n",
      "        [0.0568, 0.9199, 0.0334, 0.4645, 0.1464],\n",
      "        [0.0339, 0.1244, 0.5611, 0.1129, 0.1008],\n",
      "        [0.0922, 0.7851, 0.0654, 0.1432, 0.6628],\n",
      "        [0.0757, 0.9285, 0.0415, 0.5680, 0.0903],\n",
      "        [0.0278, 0.7911, 0.0644, 0.1583, 0.1462],\n",
      "        [0.0928, 0.9169, 0.0488, 0.6913, 0.0874],\n",
      "        [0.3123, 0.9348, 0.0406, 0.5210, 0.4554],\n",
      "        [0.0679, 0.4503, 0.1769, 0.2067, 0.2604],\n",
      "        [0.1141, 0.6080, 0.1193, 0.2543, 0.4836],\n",
      "        [0.0409, 0.1752, 0.4429, 0.0518, 0.4047],\n",
      "        [0.1455, 0.9378, 0.0431, 0.6998, 0.1062],\n",
      "        [0.0428, 0.4393, 0.1955, 0.1720, 0.2290],\n",
      "        [0.0442, 0.0968, 0.6778, 0.0583, 0.2481],\n",
      "        [0.3352, 0.6810, 0.1216, 0.2459, 0.7401],\n",
      "        [0.0388, 0.5206, 0.2512, 0.4027, 0.0552],\n",
      "        [0.0302, 0.1434, 0.6071, 0.0967, 0.0959],\n",
      "        [0.1990, 0.8949, 0.0437, 0.2793, 0.6522],\n",
      "        [0.0213, 0.4647, 0.1751, 0.0696, 0.1630],\n",
      "        [0.0512, 0.8799, 0.0432, 0.3914, 0.1490],\n",
      "        [0.0287, 0.5173, 0.2443, 0.2657, 0.0554],\n",
      "        [0.1033, 0.9268, 0.0473, 0.6909, 0.0851],\n",
      "        [0.0417, 0.8940, 0.0469, 0.3882, 0.0865],\n",
      "        [0.2036, 0.6305, 0.1398, 0.1343, 0.7786],\n",
      "        [0.0609, 0.8722, 0.0696, 0.6196, 0.0650],\n",
      "        [0.0544, 0.9097, 0.0500, 0.5200, 0.0766],\n",
      "        [0.0738, 0.0625, 0.8090, 0.1079, 0.1900],\n",
      "        [0.0440, 0.1018, 0.7118, 0.0686, 0.2525],\n",
      "        [0.2529, 0.8060, 0.0700, 0.2100, 0.7472],\n",
      "        [0.0537, 0.1673, 0.4484, 0.0601, 0.4501],\n",
      "        [0.1452, 0.9124, 0.0450, 0.7532, 0.1443],\n",
      "        [0.0849, 0.2131, 0.4224, 0.0695, 0.5595],\n",
      "        [0.0515, 0.1037, 0.6974, 0.1486, 0.1056],\n",
      "        [0.1775, 0.6951, 0.1010, 0.1569, 0.7677],\n",
      "        [0.0552, 0.1697, 0.4754, 0.0562, 0.4635],\n",
      "        [0.1157, 0.9261, 0.0499, 0.7076, 0.0846],\n",
      "        [0.0676, 0.8930, 0.0662, 0.6081, 0.0585],\n",
      "        [0.1433, 0.9506, 0.0332, 0.6312, 0.1502],\n",
      "        [0.0445, 0.7818, 0.0756, 0.4342, 0.1137],\n",
      "        [0.0736, 0.2809, 0.2883, 0.0677, 0.6188],\n",
      "        [0.1815, 0.9332, 0.0366, 0.7369, 0.1669],\n",
      "        [0.0625, 0.0925, 0.7480, 0.0713, 0.2913],\n",
      "        [0.1039, 0.8641, 0.0457, 0.5921, 0.2423],\n",
      "        [0.1860, 0.7060, 0.1070, 0.3755, 0.4609],\n",
      "        [0.0482, 0.8793, 0.0612, 0.5439, 0.0728],\n",
      "        [0.1269, 0.9461, 0.0366, 0.6077, 0.1215],\n",
      "        [0.0739, 0.6867, 0.0818, 0.1138, 0.6047],\n",
      "        [0.1290, 0.9067, 0.0330, 0.3359, 0.5211],\n",
      "        [0.3002, 0.9392, 0.0372, 0.5993, 0.4032],\n",
      "        [0.2036, 0.9460, 0.0304, 0.6087, 0.2824],\n",
      "        [0.0340, 0.8016, 0.0608, 0.3701, 0.1104],\n",
      "        [0.4376, 0.7853, 0.0963, 0.2975, 0.7698],\n",
      "        [0.0550, 0.9198, 0.0308, 0.4144, 0.1871],\n",
      "        [0.0804, 0.9178, 0.0521, 0.6059, 0.0723],\n",
      "        [0.0272, 0.5772, 0.1262, 0.0728, 0.2802],\n",
      "        [0.0616, 0.8744, 0.0393, 0.1881, 0.4222],\n",
      "        [0.0375, 0.5970, 0.1334, 0.0673, 0.3813],\n",
      "        [0.0232, 0.5551, 0.1808, 0.1946, 0.0628],\n",
      "        [0.2840, 0.8074, 0.0755, 0.2637, 0.7431],\n",
      "        [0.0921, 0.9268, 0.0284, 0.3565, 0.3738],\n",
      "        [0.0202, 0.5962, 0.1355, 0.1606, 0.0924],\n",
      "        [0.0333, 0.2941, 0.3289, 0.0486, 0.3649],\n",
      "        [0.0804, 0.8261, 0.0910, 0.7038, 0.0693],\n",
      "        [0.0236, 0.6035, 0.1272, 0.2025, 0.0805],\n",
      "        [0.0611, 0.3935, 0.3289, 0.3906, 0.0903],\n",
      "        [0.4041, 0.9033, 0.0502, 0.6457, 0.4200],\n",
      "        [0.0212, 0.5658, 0.1409, 0.0788, 0.1595],\n",
      "        [0.1813, 0.7739, 0.0711, 0.2117, 0.7186],\n",
      "        [0.0739, 0.6617, 0.1086, 0.0874, 0.6499],\n",
      "        [0.0675, 0.9057, 0.0499, 0.5761, 0.0733],\n",
      "        [0.0279, 0.2470, 0.4241, 0.1843, 0.0695],\n",
      "        [0.1929, 0.8143, 0.0618, 0.2076, 0.7691]])\n",
      "tensor([[0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [1, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [1, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [1, 1, 0, 1, 1],\n",
      "        [1, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [1, 1, 0, 1, 1],\n",
      "        [1, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 0, 1, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 0, 1, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 1],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 0, 1, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [1, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [1, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Code to generate a .csv for the dev set to submit to SemEval competition.\n",
    "\n",
    "predictions = trainer.predict(tokenized_dev) # logits\n",
    "probs = torch.sigmoid(torch.from_numpy(predictions.predictions)) # percentage probabilities\n",
    "print(\"PROBS: \", probs)\n",
    "binary_predictions = (probs >= 0.35).long()\n",
    "print(binary_predictions)\n",
    "\n",
    "# Convert tensors to integers\n",
    "binary_predictions_list = binary_predictions.tolist()\n",
    "\n",
    "\n",
    "ids = []\n",
    "for i in range(0, len(binary_predictions_list)):\n",
    "  ids.append(\"text\" + str(i))\n",
    "\n",
    "data = {\n",
    "    \"id\": ids,\n",
    "    \"Anger\": [pred[0] for pred in binary_predictions_list],\n",
    "    \"Fear\": [pred[1] for pred in binary_predictions_list],\n",
    "    \"Joy\": [pred[2] for pred in binary_predictions_list],\n",
    "    \"Sadness\": [pred[3] for pred in binary_predictions_list],\n",
    "    \"Surprise\": [pred[4] for pred in binary_predictions_list],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"pred_eng_a.csv\", index=False) # drop the index column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISCONTINUIED GRID SEARCH CODE\n",
    "\n",
    "# possible_learn_rate = [2e-4, 2e-5, 2e-6]\n",
    "# possible_batch_size = [8, 16, 32]\n",
    "\n",
    "\n",
    "# for learn_r in possible_learn_rate:\n",
    "#    for batch_s in possible_batch_size:\n",
    "#       training_args = TrainingArguments(\n",
    "#          output_dir=\"my_awesome_model\",\n",
    "#          per_device_train_batch_size = batch_s,\n",
    "#          learning_rate= learn_r,\n",
    "#          # per_device_train_batch_size=3,\n",
    "#          # per_device_eval_batch_size=3,\n",
    "#          num_train_epochs=3,\n",
    "#          weight_decay=0.01,\n",
    "#          evaluation_strategy=\"epoch\",\n",
    "#          save_strategy=\"epoch\",\n",
    "#          load_best_model_at_end=True,\n",
    "#       )\n",
    "\n",
    "#       trainer = Trainer(\n",
    "\n",
    "#          model=model,\n",
    "#          args=training_args,\n",
    "#          train_dataset=tokenized_train,\n",
    "#          eval_dataset=tokenized_test      ,\n",
    "#          tokenizer=tokenizer,\n",
    "#          data_collator=data_collator,\n",
    "#          compute_metrics=compute_metrics,\n",
    "#          # mini_batch_sizee = b_s\n",
    "#       )\n",
    "\n",
    "#       trainer.train()\n",
    "#       predictions = trainer.predict(tokenized_test)\n",
    "#       probs = sigmoid(torch.from_numpy(predictions.predictions))\n",
    "#       # print(\"PROBS: \", probs)\n",
    "#       # print(\"LABELS: \", torch.tensor(tokenized_test['label'])) # trues\n",
    "#       print(f\"LOG: Learn: {learn_r} Batch: {batch_s}\")\n",
    "#       for thresh in [0.35, 0.4, 0.45, 0.5]:\n",
    "#       # binarize predictions\n",
    "#          binary_predictions = (probs >= thresh).long()\n",
    "#          print(\"THRESH = \", thresh)\n",
    "#          # print(\"PREDS: \", binary_predictions)\n",
    "\n",
    "#          print(f1_score(y_true=tokenized_test['label'], y_pred=binary_predictions, average='weighted'))\n",
    "#          print(f1_score(y_true=tokenized_test['label'], y_pred=binary_predictions, average='micro'))\n",
    "#          print(f1_score(y_true=tokenized_test['label'], y_pred=binary_predictions, average='macro'))\n",
    "#          print(\"==============\")\n",
    "#       nums = np.round(np.linspace(.3, .7, 40), 2)\n",
    "#       final_nums = np.append(nums, 0.5)\n",
    "\n",
    "#       best_thresh = 0\n",
    "#       best_f1 = 0\n",
    "#       for curr_thresh in final_nums:\n",
    "#       # binarize predictions\n",
    "#          binary_predictions = (probs >= curr_thresh).long()\n",
    "         \n",
    "#          # print(\"PREDS: \", binary_predictions)\n",
    "\n",
    "#          curr_f1 = f1_score(y_true=tokenized_test['label'], y_pred=binary_predictions, average='weighted')\n",
    "#          if curr_f1 > best_f1:\n",
    "#             best_f1 = curr_f1\n",
    "#             best_thresh = curr_thresh\n",
    "#       # print(\"THRESH = \", curr_thresh, \" F1 = \", curr_f1)\n",
    "#       print(f\"F1: {best_f1}\")\n",
    "#       print(best_thresh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semeval1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
