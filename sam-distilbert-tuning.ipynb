{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment check \n",
    "# Return to HW0 if you run into errors in this cell \n",
    "# Do not modify this cell \n",
    "import os\n",
    "assert os.environ['CONDA_DEFAULT_ENV'] == \"cs375\"\n",
    "\n",
    "import sys\n",
    "assert sys.version_info.major == 3 and sys.version_info.minor == 11\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, \n",
    "                          TrainingArguments, Trainer, DataCollatorWithPadding, TrainingArguments)\n",
    "from datasets import Dataset, load_dataset, load_metric\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"csv\", data_files=\"/Users/samuelwexler/Library/CloudStorage/GoogleDrive-saw9@williams.edu/My Drive/Fall 2024/CSCI 375/Final Project!/eng_train.csv\", split=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SET UP DATASET OF TRAINING SET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0332879581884fdaaecd2202b16dbaa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2629 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9512633f05344ff3a22cbe39dbedbca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/139 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"No noise at all, no lights, it wasn't pitch black either.\", 'label': [0, 1, 0, 0, 1], 'input_ids': [101, 2053, 5005, 2012, 2035, 1010, 2053, 4597, 1010, 2009, 2347, 1005, 1056, 6510, 2304, 2593, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# make vectors for example and labels\n",
    "examples = []\n",
    "y_true = []\n",
    "\n",
    "for example in dataset['train']:\n",
    "  examples.append(example['text'])\n",
    "  y_true.append([example['Anger'], example['Fear'], example['Joy'], example['Sadness'], example['Surprise']])\n",
    "\n",
    "# make training and validation sets\n",
    "examples_train, examples_test, labels_train, labels_test = train_test_split(examples, y_true, test_size=0.05, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_dict( {\"text\": examples_train, \"label\": labels_train} )\n",
    "test_dataset = Dataset.from_dict( {\"text\": examples_test, \"label\": labels_test} )\n",
    "\n",
    "\n",
    "# tokenize examples\n",
    "model_name = \"distilbert/distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, clean_up_tokenization_spaces=True)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# make tokenized Datasets\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(tokenized_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CREATE CUSTOM TRAINER BASED ON CLASS WEIGHTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.huggingface.co/t/how-can-i-use-class-weights-when-training/1067/6\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "  def compute_loss(self, model, inputs, return_outputs=False):\n",
    "\n",
    "    # get class frequencies\n",
    "    train_labels_np = np.array(train_dataset['label'])\n",
    "    test_labels_np = np.array(test_dataset['label'])\n",
    "    class_freqs = torch.from_numpy(train_labels_np.sum(axis=0) + test_labels_np.sum(axis=0))\n",
    "\n",
    "    # turn freqs into weights\n",
    "    class_weights = class_freqs / sum(class_freqs)\n",
    "    class_weights = max(class_freqs) / class_freqs \n",
    "    class_weights[4] = class_weights[4] * .8 # during testing the model was overpredicting the last emotion\n",
    "\n",
    "    # standard loss things\n",
    "    labels = inputs.get(\"labels\")\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.get('logits')\n",
    "\n",
    "    loss_fct = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "    loss = loss_fct(logits, labels)\n",
    "\n",
    "    return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEFINE HOW MUCH DATA WILL BE USED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define how much data will be used\n",
    "\n",
    "percent_used = 0.6\n",
    "\n",
    "examples_in_train = round(percent_used * len(tokenized_train))\n",
    "examples_in_test = round(percent_used * len(tokenized_test))\n",
    "\n",
    "mini_tokenized_train = tokenized_train.select(range(examples_in_train)) # make so works with percent_used\n",
    "mini_tokenized_test = tokenized_test.select(range(examples_in_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINING WITH CUSTOM TRAINER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba82226f268846949226dd18c96efa32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813aa0f714ca42eb90d8b681b5acb730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6502947807312012, 'eval_runtime': 28.6965, 'eval_samples_per_second': 2.892, 'eval_steps_per_second': 0.383, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72838360006c4f8c867864c2257d76b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6452380418777466, 'eval_runtime': 30.6039, 'eval_samples_per_second': 2.712, 'eval_steps_per_second': 0.359, 'epoch': 2.0}\n",
      "{'loss': 0.5344, 'grad_norm': 2.934779167175293, 'learning_rate': 7.912457912457913e-06, 'epoch': 2.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3bad73f0474c2f9149ae09bf1051f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.67934250831604, 'eval_runtime': 30.0498, 'eval_samples_per_second': 2.762, 'eval_steps_per_second': 0.366, 'epoch': 3.0}\n",
      "{'train_runtime': 7099.6294, 'train_samples_per_second': 0.666, 'train_steps_per_second': 0.084, 'train_loss': 0.4980009477146547, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=594, training_loss=0.4980009477146547, metrics={'train_runtime': 7099.6294, 'train_samples_per_second': 0.666, 'train_steps_per_second': 0.084, 'total_flos': 626736792130560.0, 'train_loss': 0.4980009477146547, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, problem_type=\"multi_label_classification\", num_labels=5)\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", eval_strategy=\"epoch\")\n",
    "trainer = CustomTrainer(model=model, args=training_args, train_dataset=mini_tokenized_train, eval_dataset=mini_tokenized_test)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GAUGE ACCURACY OF CUSTOM TRAINER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fccfb67b18db4d4abcc54aee9a854b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBS:  tensor([[0.0488, 0.8669, 0.0444, 0.5307, 0.0258],\n",
      "        [0.0138, 0.7753, 0.0353, 0.4531, 0.1424],\n",
      "        [0.7189, 0.3654, 0.1160, 0.5101, 0.0876],\n",
      "        [0.0276, 0.6898, 0.2749, 0.0790, 0.2707],\n",
      "        [0.4073, 0.9182, 0.0277, 0.9450, 0.6171],\n",
      "        [0.1895, 0.8105, 0.0303, 0.7332, 0.5109],\n",
      "        [0.0891, 0.9058, 0.0258, 0.8528, 0.0319],\n",
      "        [0.0295, 0.5813, 0.1133, 0.9103, 0.0574],\n",
      "        [0.0730, 0.9641, 0.0280, 0.5644, 0.6592],\n",
      "        [0.0143, 0.8499, 0.0511, 0.0774, 0.6118],\n",
      "        [0.0208, 0.9313, 0.0337, 0.4777, 0.0533],\n",
      "        [0.0261, 0.9084, 0.0558, 0.5583, 0.8235],\n",
      "        [0.1398, 0.9253, 0.0520, 0.2603, 0.9304],\n",
      "        [0.0721, 0.8815, 0.0339, 0.2737, 0.9069],\n",
      "        [0.0164, 0.6493, 0.1423, 0.4754, 0.0290],\n",
      "        [0.1643, 0.9666, 0.0197, 0.8929, 0.1386],\n",
      "        [0.6639, 0.8990, 0.0394, 0.1348, 0.5258],\n",
      "        [0.7042, 0.7240, 0.0434, 0.7725, 0.0712],\n",
      "        [0.0789, 0.2070, 0.8806, 0.0288, 0.6979],\n",
      "        [0.5044, 0.6889, 0.0592, 0.9410, 0.0470],\n",
      "        [0.0623, 0.1038, 0.9731, 0.0738, 0.1231],\n",
      "        [0.9054, 0.4504, 0.0877, 0.4917, 0.2292],\n",
      "        [0.1731, 0.9030, 0.0245, 0.7205, 0.0859],\n",
      "        [0.0172, 0.9170, 0.0506, 0.0994, 0.1515],\n",
      "        [0.0304, 0.5020, 0.2678, 0.0320, 0.7301],\n",
      "        [0.0203, 0.1229, 0.6645, 0.0651, 0.3821],\n",
      "        [0.0471, 0.8725, 0.0479, 0.0959, 0.9393],\n",
      "        [0.1573, 0.1136, 0.5875, 0.2094, 0.1624],\n",
      "        [0.9394, 0.8801, 0.0371, 0.7015, 0.3193],\n",
      "        [0.0116, 0.4693, 0.1005, 0.1346, 0.2632],\n",
      "        [0.8206, 0.6349, 0.0710, 0.1728, 0.7574],\n",
      "        [0.0333, 0.9670, 0.0213, 0.3623, 0.3889],\n",
      "        [0.0342, 0.2459, 0.6201, 0.0269, 0.0567],\n",
      "        [0.0716, 0.9427, 0.0244, 0.9339, 0.1361],\n",
      "        [0.0312, 0.3875, 0.5264, 0.0348, 0.0915],\n",
      "        [0.4911, 0.9537, 0.0187, 0.8506, 0.7321],\n",
      "        [0.8770, 0.8202, 0.0395, 0.7893, 0.5204],\n",
      "        [0.0342, 0.3404, 0.3476, 0.2160, 0.0588],\n",
      "        [0.0372, 0.2043, 0.5848, 0.0214, 0.5923],\n",
      "        [0.0569, 0.6883, 0.0415, 0.3219, 0.0348],\n",
      "        [0.0171, 0.4782, 0.2881, 0.3340, 0.0217],\n",
      "        [0.4920, 0.9611, 0.0244, 0.7168, 0.8313],\n",
      "        [0.0180, 0.8207, 0.1335, 0.1161, 0.4810],\n",
      "        [0.2214, 0.5453, 0.0972, 0.5247, 0.0354],\n",
      "        [0.0093, 0.8247, 0.0654, 0.5091, 0.1157],\n",
      "        [0.0331, 0.6827, 0.1147, 0.9401, 0.0807],\n",
      "        [0.0215, 0.8469, 0.0699, 0.1313, 0.0577],\n",
      "        [0.0982, 0.0854, 0.9780, 0.0927, 0.2690],\n",
      "        [0.0533, 0.7891, 0.0297, 0.7870, 0.0585],\n",
      "        [0.0214, 0.8572, 0.0513, 0.3501, 0.0343],\n",
      "        [0.0559, 0.0889, 0.7978, 0.0354, 0.2690],\n",
      "        [0.0347, 0.3841, 0.2608, 0.8971, 0.0453],\n",
      "        [0.0688, 0.0853, 0.9635, 0.0498, 0.1301],\n",
      "        [0.0707, 0.2153, 0.8814, 0.0377, 0.5601],\n",
      "        [0.0878, 0.1336, 0.7643, 0.0201, 0.4388],\n",
      "        [0.0664, 0.9438, 0.0213, 0.9098, 0.0661],\n",
      "        [0.0379, 0.1762, 0.5521, 0.0575, 0.0413],\n",
      "        [0.0351, 0.6805, 0.1771, 0.0306, 0.4289],\n",
      "        [0.0182, 0.5829, 0.1820, 0.0533, 0.0734],\n",
      "        [0.0298, 0.8574, 0.0456, 0.2691, 0.0422],\n",
      "        [0.0417, 0.1960, 0.7892, 0.0174, 0.5190],\n",
      "        [0.0304, 0.2035, 0.6158, 0.0848, 0.0248],\n",
      "        [0.0111, 0.6999, 0.0723, 0.3156, 0.1182],\n",
      "        [0.0564, 0.8703, 0.0749, 0.0969, 0.9616],\n",
      "        [0.0913, 0.2241, 0.9285, 0.0591, 0.7260],\n",
      "        [0.0401, 0.2078, 0.5470, 0.8092, 0.1592],\n",
      "        [0.4562, 0.9519, 0.0230, 0.6888, 0.5684],\n",
      "        [0.0575, 0.4085, 0.2761, 0.0233, 0.2414],\n",
      "        [0.0170, 0.5881, 0.0457, 0.3139, 0.2413],\n",
      "        [0.0261, 0.9076, 0.0341, 0.6267, 0.0333],\n",
      "        [0.0143, 0.8259, 0.0383, 0.6210, 0.0475],\n",
      "        [0.4495, 0.9442, 0.0238, 0.5231, 0.9073],\n",
      "        [0.4281, 0.9078, 0.0228, 0.7486, 0.0851],\n",
      "        [0.0823, 0.6618, 0.0469, 0.9561, 0.1065],\n",
      "        [0.1098, 0.9565, 0.0300, 0.8039, 0.6992],\n",
      "        [0.8797, 0.7787, 0.0442, 0.5330, 0.4266],\n",
      "        [0.0292, 0.9356, 0.0351, 0.1284, 0.1524],\n",
      "        [0.0622, 0.7562, 0.1386, 0.0368, 0.9454],\n",
      "        [0.0565, 0.4040, 0.2274, 0.0576, 0.6644],\n",
      "        [0.0369, 0.6225, 0.1980, 0.0764, 0.0443],\n",
      "        [0.0518, 0.2473, 0.6182, 0.0904, 0.0350],\n",
      "        [0.2101, 0.4575, 0.1701, 0.9598, 0.1766],\n",
      "        [0.5499, 0.9624, 0.0198, 0.7914, 0.7899]])\n",
      "LABELS:  tensor([[0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [1, 1, 0, 1, 0],\n",
      "        [1, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 1],\n",
      "        [1, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [1, 1, 0, 0, 1],\n",
      "        [1, 1, 0, 1, 1],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [1, 1, 0, 0, 1],\n",
      "        [0, 1, 1, 0, 1],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [1, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 1, 0, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 1],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 0, 1, 0, 1],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [1, 1, 0, 1, 1]])\n",
      "THRESH =  0.35\n",
      "0.6832000471255355\n",
      "0.6777408637873754\n",
      "0.620130954547129\n",
      "==============\n",
      "THRESH =  0.4\n",
      "0.6876423093814399\n",
      "0.6802721088435374\n",
      "0.6238779095300835\n",
      "==============\n",
      "THRESH =  0.45\n",
      "0.6815522171940288\n",
      "0.6783216783216783\n",
      "0.6258764593637871\n",
      "==============\n",
      "THRESH =  0.5\n",
      "0.680138001766961\n",
      "0.6788321167883211\n",
      "0.6170415205709323\n",
      "==============\n",
      "THRESH =  0.55\n",
      "0.6804535604867018\n",
      "0.6821705426356589\n",
      "0.5900602262690835\n",
      "==============\n",
      "THRESH =  0.6\n",
      "0.6682397622014704\n",
      "0.6720647773279352\n",
      "0.5849323234448418\n",
      "==============\n",
      "THRESH =  0.65\n",
      "0.6734652581461091\n",
      "0.6751054852320675\n",
      "0.5982707930367506\n",
      "==============\n"
     ]
    }
   ],
   "source": [
    "# get result of training\n",
    "predictions = trainer.predict(mini_tokenized_test) # logits\n",
    "probs = torch.sigmoid(torch.from_numpy(predictions.predictions)) # percentage probabilities\n",
    "print(\"PROBS: \", probs)\n",
    "print(\"LABELS: \", torch.tensor(mini_tokenized_test['label'])) # trues\n",
    "\n",
    "for thresh in [0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65]:\n",
    "  # binarize predictions\n",
    "  binary_predictions = (probs >= thresh).long()\n",
    "  print(\"THRESH = \", thresh)\n",
    "\n",
    "  # get F1 scores\n",
    "  print(f1_score(y_true=mini_tokenized_test['label'], y_pred=binary_predictions, average='weighted'))\n",
    "  print(f1_score(y_true=mini_tokenized_test['label'], y_pred=binary_predictions, average='micro'))\n",
    "  print(f1_score(y_true=mini_tokenized_test['label'], y_pred=binary_predictions, average='macro'))\n",
    "  print(\"==============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GAUGE PERFORMANCE BY EMOTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ =  tensor(333)\n",
      "COL =  0\n",
      "0.8546863510379545\n",
      "0.8313253012048193\n",
      "0.659037558685446\n",
      "==========================\n",
      "FREQ =  tensor(1611)\n",
      "COL =  1\n",
      "0.61547338780409\n",
      "0.6385542168674698\n",
      "0.6024904214559387\n",
      "==========================\n",
      "FREQ =  tensor(674)\n",
      "COL =  2\n",
      "0.8021806981857711\n",
      "0.7951807228915663\n",
      "0.6785144679881522\n",
      "==========================\n",
      "FREQ =  tensor(878)\n",
      "COL =  3\n",
      "0.7506925955727887\n",
      "0.7469879518072289\n",
      "0.7395786642761093\n",
      "==========================\n",
      "FREQ =  tensor(839)\n",
      "COL =  4\n",
      "0.8554216867469879\n",
      "0.8554216867469879\n",
      "0.8433962264150944\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "# results by label\n",
    "binary_predictions_final = (probs >= 0.4).long()\n",
    "labels = torch.tensor(mini_tokenized_test['label'])\n",
    "\n",
    "train_labels_np = np.array(train_dataset['label'])\n",
    "test_labels_np = np.array(test_dataset['label'])\n",
    "class_freqs = torch.from_numpy(train_labels_np.sum(axis=0) + test_labels_np.sum(axis=0))\n",
    "\n",
    "for col in range(0, 5):\n",
    "  print(\"FREQ = \", class_freqs[col])\n",
    "  print(\"COL = \", col)\n",
    "  print(f1_score(y_true=labels[:, col], y_pred=binary_predictions_final[:, col], average='weighted'))\n",
    "  print(f1_score(y_true=labels[:, col], y_pred=binary_predictions_final[:, col], average='micro'))\n",
    "  print(f1_score(y_true=labels[:, col], y_pred=binary_predictions_final[:, col], average='macro'))\n",
    "  print(\"==========================\")\n",
    "\n",
    "\n",
    "# # get F1 scores\n",
    "# print(f1_score(y_true=mini_tokenized_test['label'], y_pred=binary_predictions, average='weighted'))\n",
    "# print(f1_score(y_true=mini_tokenized_test['label'], y_pred=binary_predictions, average='micro'))\n",
    "# print(f1_score(y_true=mini_tokenized_test['label'], y_pred=binary_predictions, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**======   EXPERIMENTS =========**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRY WITHOUT CLASS WEIGHTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213e7e852e194004b03bef94dd15c85b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1702e94655e4314b90068b1d805c237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45320937037467957, 'eval_runtime': 25.8625, 'eval_samples_per_second': 3.209, 'eval_steps_per_second': 0.425, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876d20f7718b436c9887e0ca6dc0bd95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42231285572052, 'eval_runtime': 39.8177, 'eval_samples_per_second': 2.084, 'eval_steps_per_second': 0.276, 'epoch': 2.0}\n",
      "{'loss': 0.3781, 'grad_norm': 1.4667855501174927, 'learning_rate': 7.912457912457913e-06, 'epoch': 2.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ad40464ca84e818751554873b896f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4267077147960663, 'eval_runtime': 27.386, 'eval_samples_per_second': 3.031, 'eval_steps_per_second': 0.402, 'epoch': 3.0}\n",
      "{'train_runtime': 8278.425, 'train_samples_per_second': 0.571, 'train_steps_per_second': 0.072, 'train_loss': 0.35377985700613723, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=594, training_loss=0.35377985700613723, metrics={'train_runtime': 8278.425, 'train_samples_per_second': 0.571, 'train_steps_per_second': 0.072, 'total_flos': 626736792130560.0, 'train_loss': 0.35377985700613723, 'epoch': 3.0})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = AutoModelForSequenceClassification.from_pretrained(model_name, problem_type=\"multi_label_classification\", num_labels=5)\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", eval_strategy=\"epoch\")\n",
    "trainer2 = Trainer(model=model2, args=training_args, train_dataset=mini_tokenized_train, eval_dataset=mini_tokenized_test)\n",
    "trainer2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5400b573994609918c60b98991f93f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBS:  tensor([[0.0487, 0.9035, 0.0242, 0.2133, 0.0202],\n",
      "        [0.0144, 0.8830, 0.0176, 0.4544, 0.0798],\n",
      "        [0.3316, 0.3466, 0.0453, 0.4799, 0.0614],\n",
      "        [0.0251, 0.4848, 0.1703, 0.0197, 0.1419],\n",
      "        [0.1587, 0.9338, 0.0324, 0.9317, 0.5442],\n",
      "        [0.3070, 0.3450, 0.0401, 0.5527, 0.1540],\n",
      "        [0.1252, 0.9405, 0.0125, 0.4739, 0.0308],\n",
      "        [0.0279, 0.5685, 0.0815, 0.8959, 0.0453],\n",
      "        [0.0458, 0.9769, 0.0211, 0.2852, 0.8038],\n",
      "        [0.0111, 0.8882, 0.0287, 0.0818, 0.5965],\n",
      "        [0.0178, 0.9450, 0.0288, 0.2186, 0.0349],\n",
      "        [0.0379, 0.9391, 0.0489, 0.3095, 0.9410],\n",
      "        [0.1028, 0.9582, 0.0328, 0.1984, 0.9232],\n",
      "        [0.0632, 0.9594, 0.0165, 0.1298, 0.8750],\n",
      "        [0.0209, 0.8848, 0.0340, 0.3872, 0.0178],\n",
      "        [0.2694, 0.9816, 0.0146, 0.7161, 0.2165],\n",
      "        [0.3501, 0.8962, 0.0262, 0.0586, 0.4778],\n",
      "        [0.0440, 0.9078, 0.0180, 0.2685, 0.0500],\n",
      "        [0.0317, 0.1833, 0.6096, 0.0250, 0.7442],\n",
      "        [0.1406, 0.5629, 0.0496, 0.7311, 0.0102],\n",
      "        [0.0188, 0.0974, 0.8620, 0.0554, 0.0431],\n",
      "        [0.5794, 0.2216, 0.0770, 0.4998, 0.0576],\n",
      "        [0.1503, 0.9236, 0.0162, 0.5013, 0.0598],\n",
      "        [0.0181, 0.9583, 0.0244, 0.0747, 0.1347],\n",
      "        [0.0192, 0.3523, 0.1942, 0.0288, 0.6670],\n",
      "        [0.0154, 0.0663, 0.6582, 0.0371, 0.3529],\n",
      "        [0.0543, 0.9485, 0.0256, 0.1266, 0.9438],\n",
      "        [0.0220, 0.1726, 0.1503, 0.0893, 0.1758],\n",
      "        [0.5262, 0.9636, 0.0162, 0.3407, 0.2834],\n",
      "        [0.0106, 0.2185, 0.1208, 0.0571, 0.0716],\n",
      "        [0.4806, 0.3116, 0.0528, 0.1507, 0.2045],\n",
      "        [0.0314, 0.9821, 0.0136, 0.2747, 0.4060],\n",
      "        [0.0148, 0.2472, 0.3289, 0.0307, 0.0198],\n",
      "        [0.0666, 0.9721, 0.0184, 0.8865, 0.1668],\n",
      "        [0.0126, 0.3822, 0.3264, 0.0217, 0.0535],\n",
      "        [0.2965, 0.9766, 0.0138, 0.6860, 0.8016],\n",
      "        [0.4294, 0.7025, 0.0208, 0.3186, 0.4665],\n",
      "        [0.0572, 0.1557, 0.1473, 0.2378, 0.0481],\n",
      "        [0.0166, 0.1865, 0.2982, 0.0210, 0.6168],\n",
      "        [0.0890, 0.8515, 0.0126, 0.1442, 0.0477],\n",
      "        [0.0114, 0.4620, 0.1334, 0.1756, 0.0133],\n",
      "        [0.1785, 0.9785, 0.0180, 0.4721, 0.8905],\n",
      "        [0.0078, 0.3843, 0.2297, 0.0611, 0.1523],\n",
      "        [0.1764, 0.6322, 0.0498, 0.3835, 0.0178],\n",
      "        [0.0064, 0.7233, 0.0834, 0.3294, 0.0778],\n",
      "        [0.0316, 0.8465, 0.0598, 0.9145, 0.0772],\n",
      "        [0.0302, 0.8442, 0.0529, 0.0482, 0.0561],\n",
      "        [0.0324, 0.0640, 0.9434, 0.0662, 0.2524],\n",
      "        [0.0745, 0.9269, 0.0121, 0.5932, 0.0605],\n",
      "        [0.0128, 0.7018, 0.0625, 0.1298, 0.0131],\n",
      "        [0.0138, 0.0778, 0.5278, 0.0218, 0.0691],\n",
      "        [0.0479, 0.5246, 0.0900, 0.9004, 0.0211],\n",
      "        [0.0269, 0.0489, 0.8773, 0.0287, 0.1623],\n",
      "        [0.0335, 0.1252, 0.8394, 0.0260, 0.4844],\n",
      "        [0.0248, 0.2527, 0.4646, 0.0146, 0.7286],\n",
      "        [0.0492, 0.9532, 0.0194, 0.8522, 0.0357],\n",
      "        [0.0128, 0.1547, 0.3014, 0.0391, 0.0250],\n",
      "        [0.0088, 0.5411, 0.1354, 0.0223, 0.1763],\n",
      "        [0.0089, 0.4720, 0.1472, 0.0512, 0.0235],\n",
      "        [0.0386, 0.9336, 0.0195, 0.3035, 0.0245],\n",
      "        [0.0174, 0.2100, 0.6615, 0.0149, 0.7133],\n",
      "        [0.0126, 0.3137, 0.2128, 0.0902, 0.0115],\n",
      "        [0.0182, 0.5627, 0.0633, 0.1483, 0.0842],\n",
      "        [0.0384, 0.9232, 0.0398, 0.0716, 0.9392],\n",
      "        [0.0344, 0.1878, 0.8507, 0.0361, 0.7617],\n",
      "        [0.0197, 0.1045, 0.5326, 0.5555, 0.0761],\n",
      "        [0.1441, 0.9638, 0.0140, 0.2765, 0.6172],\n",
      "        [0.0209, 0.3976, 0.1486, 0.0171, 0.0848],\n",
      "        [0.0250, 0.4302, 0.0361, 0.1925, 0.0520],\n",
      "        [0.0300, 0.9530, 0.0191, 0.6128, 0.0249],\n",
      "        [0.0120, 0.8556, 0.0299, 0.4953, 0.0218],\n",
      "        [0.1514, 0.9668, 0.0179, 0.2648, 0.9322],\n",
      "        [0.1985, 0.8832, 0.0151, 0.5687, 0.0300],\n",
      "        [0.0779, 0.4604, 0.0475, 0.8589, 0.0449],\n",
      "        [0.1761, 0.9661, 0.0240, 0.4664, 0.5180],\n",
      "        [0.1508, 0.9218, 0.0166, 0.0706, 0.4060],\n",
      "        [0.0322, 0.9709, 0.0198, 0.0892, 0.1246],\n",
      "        [0.0246, 0.6530, 0.1761, 0.0197, 0.9264],\n",
      "        [0.0448, 0.5833, 0.0585, 0.0365, 0.4471],\n",
      "        [0.0178, 0.5101, 0.1140, 0.0536, 0.0180],\n",
      "        [0.0229, 0.1347, 0.4589, 0.0393, 0.0223],\n",
      "        [0.1316, 0.3863, 0.1026, 0.9134, 0.1440],\n",
      "        [0.2393, 0.9828, 0.0143, 0.5528, 0.7549]])\n",
      "THRESH =  0.35\n",
      "0.6643541706501518\n",
      "0.6717557251908397\n",
      "0.5993152754375916\n",
      "==============\n",
      "THRESH =  0.4\n",
      "0.6697397689450842\n",
      "0.6798418972332015\n",
      "0.5814692120841157\n",
      "==============\n",
      "THRESH =  0.45\n",
      "0.6629755799755801\n",
      "0.6774193548387096\n",
      "0.5503809523809524\n",
      "==============\n",
      "THRESH =  0.5\n",
      "0.6407517622433588\n",
      "0.658008658008658\n",
      "0.5374587835134054\n",
      "==============\n",
      "THRESH =  0.55\n",
      "0.638221931344552\n",
      "0.6576576576576577\n",
      "0.540809170793142\n",
      "==============\n",
      "THRESH =  0.6\n",
      "0.6139045708497884\n",
      "0.6445497630331753\n",
      "0.5173270204458784\n",
      "==============\n",
      "THRESH =  0.65\n",
      "0.6095860661078053\n",
      "0.6407766990291263\n",
      "0.5066629023150762\n",
      "==============\n"
     ]
    }
   ],
   "source": [
    "# get result of training\n",
    "predictions = trainer2.predict(mini_tokenized_test) # logits\n",
    "probs = torch.sigmoid(torch.from_numpy(predictions.predictions)) # percentage probabilities\n",
    "\n",
    "probs_array = probs.numpy()\n",
    "# formatted_probs = np.array([[f\"{value:.6f}\" for value in row] for row in probs_array])\n",
    "\n",
    "print(\"PROBS: \", probs)\n",
    "# print(\"LABELS: \", torch.tensor(mini_tokenized_test['label'])) # trues\n",
    "\n",
    "for thresh in [0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65]:\n",
    "  # binarize predictions\n",
    "  binary_predictions = (probs >= thresh).long()\n",
    "  print(\"THRESH = \", thresh)\n",
    "\n",
    "  # get F1 scores\n",
    "  print(f1_score(y_true=mini_tokenized_test['label'], y_pred=binary_predictions, average='weighted'))\n",
    "  print(f1_score(y_true=mini_tokenized_test['label'], y_pred=binary_predictions, average='micro'))\n",
    "  print(f1_score(y_true=mini_tokenized_test['label'], y_pred=binary_predictions, average='macro'))\n",
    "  print(\"==============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRID SEARCH TO FIND BEST PARAMETER SET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==TESTING WITH LR = 2*10^-4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f051fb698c14e45acc21a9596e9b25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4de14b15be4a1585bfeb6e47727b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.538555920124054, 'eval_runtime': 39.3841, 'eval_samples_per_second': 2.107, 'eval_steps_per_second': 0.279, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff1a6d1293e4b109e059faaae263c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.523768424987793, 'eval_runtime': 48.1267, 'eval_samples_per_second': 1.725, 'eval_steps_per_second': 0.229, 'epoch': 2.0}\n",
      "{'loss': 0.4235, 'grad_norm': 1.8284848928451538, 'learning_rate': 3.164983164983165e-05, 'epoch': 2.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92683eee2771468d935b81d26020e638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5231296420097351, 'eval_runtime': 41.34, 'eval_samples_per_second': 2.008, 'eval_steps_per_second': 0.266, 'epoch': 3.0}\n",
      "{'train_runtime': 9253.6355, 'train_samples_per_second': 0.511, 'train_steps_per_second': 0.064, 'train_loss': 0.39413174394806627, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959a05f410414043bd02fb02da314f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/297 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9e3b43b0324e3ebf043bba2868c9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4815734624862671, 'eval_runtime': 41.5491, 'eval_samples_per_second': 1.998, 'eval_steps_per_second': 0.265, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306293a562f942f48eb28e231f530376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4870759844779968, 'eval_runtime': 45.9219, 'eval_samples_per_second': 1.807, 'eval_steps_per_second': 0.24, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9b86eea9b94b639f04490c9a7b2db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5103946328163147, 'eval_runtime': 31.6212, 'eval_samples_per_second': 2.625, 'eval_steps_per_second': 0.348, 'epoch': 3.0}\n",
      "{'train_runtime': 10495.9691, 'train_samples_per_second': 0.451, 'train_steps_per_second': 0.028, 'train_loss': 0.3412875294283986, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616dc49ad4b148e7b8c639260377ed6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff60906156c4322ba0ecba31e01dcbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4829866290092468, 'eval_runtime': 43.9648, 'eval_samples_per_second': 1.888, 'eval_steps_per_second': 0.25, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6db2c25dae4b6ab37d36219b3ac810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45964980125427246, 'eval_runtime': 37.2359, 'eval_samples_per_second': 2.229, 'eval_steps_per_second': 0.295, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e9ff4bec744cc9a0a42ef1f27ccfbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4627303183078766, 'eval_runtime': 37.097, 'eval_samples_per_second': 2.237, 'eval_steps_per_second': 0.297, 'epoch': 3.0}\n",
      "{'train_runtime': 9950.8428, 'train_samples_per_second': 0.475, 'train_steps_per_second': 0.015, 'train_loss': 0.3673821258544922, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# learning_rates = [2e-4, 2e-5, 2e-6]\n",
    "learning_rates = [2e-4]\n",
    "batch_sizes = [8, 16, 32]\n",
    "experiments = {}\n",
    "\n",
    "trial_num = 0\n",
    "for curr_learning_rate in learning_rates:\n",
    "  for curr_batch_size in batch_sizes:\n",
    "    experiments[trial_num] = {}\n",
    "    experiments[trial_num][\"model\"] = AutoModelForSequenceClassification.from_pretrained(model_name, problem_type=\"multi_label_classification\", num_labels=5)\n",
    "    experiments[trial_num][\"training_args\"] = TrainingArguments(output_dir=\"test_trainer\", \n",
    "                                                                eval_strategy=\"epoch\", \n",
    "                                                                per_device_train_batch_size=curr_batch_size, \n",
    "                                                                learning_rate=curr_learning_rate)\n",
    "    experiments[trial_num][\"trainer\"] = Trainer(model=experiments[trial_num][\"model\"], \n",
    "                                                args=experiments[trial_num][\"training_args\"], \n",
    "                                                train_dataset=mini_tokenized_train, \n",
    "                                                eval_dataset=mini_tokenized_test)\n",
    "    experiments[trial_num][\"trainer\"].train()\n",
    "    \n",
    "    trial_num = trial_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e7f0e8507b41fd8edcec6fdcc22811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBS:  tensor([[0.0290, 0.9552, 0.0164, 0.6467, 0.0086],\n",
      "        [0.0048, 0.5757, 0.0440, 0.0557, 0.0255],\n",
      "        [0.1203, 0.1113, 0.1465, 0.5364, 0.0511],\n",
      "        [0.0753, 0.9262, 0.0412, 0.0423, 0.9568],\n",
      "        [0.3931, 0.8804, 0.0147, 0.9289, 0.4590],\n",
      "        [0.4277, 0.4675, 0.0316, 0.6477, 0.5681],\n",
      "        [0.1069, 0.9403, 0.0163, 0.8428, 0.0154],\n",
      "        [0.0066, 0.0361, 0.5789, 0.2649, 0.0150],\n",
      "        [0.0151, 0.9803, 0.0151, 0.0969, 0.1503],\n",
      "        [0.0175, 0.4081, 0.0436, 0.0713, 0.4843],\n",
      "        [0.0325, 0.9770, 0.0113, 0.7049, 0.0170],\n",
      "        [0.0288, 0.6539, 0.2292, 0.0484, 0.9837],\n",
      "        [0.0515, 0.9824, 0.0099, 0.2814, 0.8505],\n",
      "        [0.0387, 0.9192, 0.0217, 0.0529, 0.9333],\n",
      "        [0.0686, 0.6385, 0.0859, 0.6613, 0.0086],\n",
      "        [0.0300, 0.9784, 0.0127, 0.4444, 0.0153],\n",
      "        [0.3601, 0.6085, 0.0491, 0.0395, 0.8228],\n",
      "        [0.2992, 0.7233, 0.0354, 0.8424, 0.0100],\n",
      "        [0.0235, 0.2970, 0.4979, 0.0165, 0.8768],\n",
      "        [0.0456, 0.9105, 0.0178, 0.7211, 0.0054],\n",
      "        [0.0092, 0.2014, 0.2858, 0.0974, 0.0046],\n",
      "        [0.5252, 0.7937, 0.0129, 0.8024, 0.0379],\n",
      "        [0.1433, 0.9349, 0.0418, 0.3634, 0.0347],\n",
      "        [0.0143, 0.9657, 0.0256, 0.0576, 0.0400],\n",
      "        [0.0191, 0.3599, 0.0731, 0.0221, 0.7916],\n",
      "        [0.0072, 0.0435, 0.7447, 0.0267, 0.4511],\n",
      "        [0.0247, 0.7590, 0.0165, 0.0771, 0.9535],\n",
      "        [0.0201, 0.0797, 0.1242, 0.7077, 0.0268],\n",
      "        [0.6230, 0.9608, 0.0128, 0.5445, 0.0534],\n",
      "        [0.0046, 0.0993, 0.2643, 0.0253, 0.0219],\n",
      "        [0.6693, 0.2644, 0.0882, 0.5088, 0.1648],\n",
      "        [0.0179, 0.9792, 0.0110, 0.1612, 0.0730],\n",
      "        [0.0070, 0.0484, 0.5506, 0.0156, 0.0252],\n",
      "        [0.0460, 0.9724, 0.0100, 0.8450, 0.0942],\n",
      "        [0.0165, 0.1408, 0.7760, 0.0163, 0.0258],\n",
      "        [0.5637, 0.9341, 0.0103, 0.6892, 0.9081],\n",
      "        [0.8976, 0.8504, 0.0137, 0.5690, 0.6763],\n",
      "        [0.1626, 0.1317, 0.2418, 0.1648, 0.1523],\n",
      "        [0.0073, 0.4703, 0.0564, 0.0139, 0.6150],\n",
      "        [0.0676, 0.8330, 0.0147, 0.2842, 0.0122],\n",
      "        [0.0049, 0.4131, 0.0946, 0.0392, 0.0083],\n",
      "        [0.1270, 0.9690, 0.0198, 0.6252, 0.4139],\n",
      "        [0.0114, 0.0861, 0.1851, 0.1678, 0.0991],\n",
      "        [0.1599, 0.1414, 0.2156, 0.4953, 0.0181],\n",
      "        [0.0082, 0.4549, 0.0453, 0.0902, 0.2744],\n",
      "        [0.0520, 0.6626, 0.0400, 0.9487, 0.0891],\n",
      "        [0.5883, 0.9601, 0.0123, 0.2456, 0.2319],\n",
      "        [0.0171, 0.0288, 0.9774, 0.0575, 0.1106],\n",
      "        [0.0699, 0.9437, 0.0145, 0.8675, 0.0151],\n",
      "        [0.0101, 0.8786, 0.0319, 0.2445, 0.0059],\n",
      "        [0.0058, 0.1143, 0.6316, 0.0110, 0.0447],\n",
      "        [0.0446, 0.3426, 0.1185, 0.8710, 0.0165],\n",
      "        [0.0102, 0.0327, 0.7391, 0.0190, 0.0708],\n",
      "        [0.4382, 0.1797, 0.5479, 0.2172, 0.2191],\n",
      "        [0.0136, 0.0279, 0.8152, 0.0192, 0.1147],\n",
      "        [0.0540, 0.9408, 0.0137, 0.9355, 0.0308],\n",
      "        [0.0059, 0.2915, 0.1205, 0.0448, 0.0063],\n",
      "        [0.0094, 0.6775, 0.1019, 0.0265, 0.0111],\n",
      "        [0.0063, 0.5967, 0.1386, 0.0176, 0.0157],\n",
      "        [0.1822, 0.9208, 0.0457, 0.2362, 0.0206],\n",
      "        [0.0094, 0.1004, 0.8962, 0.0105, 0.2370],\n",
      "        [0.0067, 0.2451, 0.1345, 0.0717, 0.0050],\n",
      "        [0.0508, 0.2775, 0.3469, 0.0898, 0.0641],\n",
      "        [0.0176, 0.7669, 0.0423, 0.0285, 0.9642],\n",
      "        [0.0853, 0.1444, 0.8061, 0.0537, 0.8531],\n",
      "        [0.0073, 0.0412, 0.4539, 0.4187, 0.0275],\n",
      "        [0.7235, 0.8948, 0.0134, 0.3829, 0.9073],\n",
      "        [0.0278, 0.6328, 0.2298, 0.0153, 0.1015],\n",
      "        [0.0076, 0.2173, 0.0592, 0.0848, 0.0194],\n",
      "        [0.0419, 0.9710, 0.0246, 0.3487, 0.0831],\n",
      "        [0.0044, 0.2275, 0.1539, 0.1446, 0.0055],\n",
      "        [0.2579, 0.9571, 0.0084, 0.4344, 0.8398],\n",
      "        [0.8474, 0.6790, 0.0344, 0.4328, 0.1853],\n",
      "        [0.0292, 0.1223, 0.1456, 0.5168, 0.1107],\n",
      "        [0.1088, 0.9685, 0.0295, 0.3322, 0.5813],\n",
      "        [0.7537, 0.8283, 0.0266, 0.5629, 0.3952],\n",
      "        [0.0152, 0.9596, 0.0332, 0.0373, 0.0550],\n",
      "        [0.3043, 0.8723, 0.0403, 0.2618, 0.6990],\n",
      "        [0.0287, 0.1400, 0.2936, 0.0413, 0.0742],\n",
      "        [0.0080, 0.4832, 0.0738, 0.0730, 0.0052],\n",
      "        [0.0109, 0.0463, 0.9430, 0.0212, 0.0418],\n",
      "        [0.1010, 0.3835, 0.0495, 0.9375, 0.0614],\n",
      "        [0.3107, 0.9541, 0.0097, 0.8676, 0.1863]])\n",
      "EXP # =  0  THRESH =  0.35  MICRO F1 =  0.6037735849056604\n",
      "EXP # =  0  THRESH =  0.4  MICRO F1 =  0.5891472868217055\n",
      "EXP # =  0  THRESH =  0.45  MICRO F1 =  0.570281124497992\n",
      "EXP # =  0  THRESH =  0.5  MICRO F1 =  0.5857740585774058\n",
      "EXP # =  0  THRESH =  0.55  MICRO F1 =  0.575107296137339\n",
      "EXP # =  0  THRESH =  0.6  MICRO F1 =  0.5829596412556054\n",
      "EXP # =  0  THRESH =  0.65  MICRO F1 =  0.5794392523364486\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97cb67a57d8344af9c9a7f0deeb69b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBS:  tensor([[0.0315, 0.9676, 0.0193, 0.1842, 0.0079],\n",
      "        [0.0042, 0.7059, 0.0359, 0.6215, 0.0102],\n",
      "        [0.2936, 0.0878, 0.0909, 0.2360, 0.0548],\n",
      "        [0.7071, 0.7094, 0.0327, 0.4308, 0.0354],\n",
      "        [0.1110, 0.8741, 0.0117, 0.9616, 0.6214],\n",
      "        [0.0876, 0.5194, 0.0551, 0.8354, 0.1109],\n",
      "        [0.1060, 0.9785, 0.0082, 0.8963, 0.0223],\n",
      "        [0.0067, 0.0948, 0.3709, 0.7692, 0.0183],\n",
      "        [0.0130, 0.9794, 0.0276, 0.0742, 0.0596],\n",
      "        [0.0037, 0.3288, 0.0478, 0.0184, 0.6340],\n",
      "        [0.0097, 0.9712, 0.0182, 0.1627, 0.0105],\n",
      "        [0.0180, 0.8601, 0.0397, 0.1773, 0.9862],\n",
      "        [0.0451, 0.9875, 0.0132, 0.3122, 0.3820],\n",
      "        [0.0084, 0.9003, 0.0582, 0.0134, 0.9578],\n",
      "        [0.0177, 0.9626, 0.0176, 0.2192, 0.0067],\n",
      "        [0.1341, 0.9905, 0.0080, 0.8221, 0.0602],\n",
      "        [0.2739, 0.9481, 0.0153, 0.0340, 0.2788],\n",
      "        [0.0203, 0.8598, 0.0227, 0.1518, 0.0079],\n",
      "        [0.0203, 0.1190, 0.8127, 0.0124, 0.8964],\n",
      "        [0.0494, 0.7223, 0.0384, 0.9319, 0.0060],\n",
      "        [0.0120, 0.0692, 0.9564, 0.0483, 0.0183],\n",
      "        [0.8458, 0.2939, 0.0264, 0.3144, 0.1039],\n",
      "        [0.0155, 0.9392, 0.0254, 0.6777, 0.0058],\n",
      "        [0.0121, 0.9729, 0.0216, 0.0248, 0.0568],\n",
      "        [0.0109, 0.1056, 0.2526, 0.0152, 0.8921],\n",
      "        [0.0061, 0.0224, 0.7544, 0.0264, 0.2850],\n",
      "        [0.0125, 0.9143, 0.0065, 0.1041, 0.7358],\n",
      "        [0.0213, 0.0202, 0.2756, 0.2571, 0.1441],\n",
      "        [0.7017, 0.9288, 0.0079, 0.3850, 0.0440],\n",
      "        [0.0057, 0.0842, 0.1304, 0.0673, 0.0218],\n",
      "        [0.7899, 0.4017, 0.0214, 0.1473, 0.1636],\n",
      "        [0.0076, 0.9891, 0.0091, 0.0916, 0.3657],\n",
      "        [0.0088, 0.2654, 0.1663, 0.0082, 0.0223],\n",
      "        [0.0172, 0.9582, 0.0113, 0.9529, 0.0666],\n",
      "        [0.0108, 0.1826, 0.7263, 0.0063, 0.0308],\n",
      "        [0.8259, 0.9607, 0.0095, 0.7036, 0.8042],\n",
      "        [0.5059, 0.5741, 0.0160, 0.3495, 0.1409],\n",
      "        [0.0092, 0.5483, 0.0383, 0.3118, 0.0083],\n",
      "        [0.0078, 0.0864, 0.2231, 0.0101, 0.2477],\n",
      "        [0.0207, 0.9072, 0.0078, 0.1144, 0.0233],\n",
      "        [0.0030, 0.2788, 0.1967, 0.1016, 0.0056],\n",
      "        [0.0458, 0.9921, 0.0058, 0.3866, 0.5957],\n",
      "        [0.0038, 0.0840, 0.5385, 0.0787, 0.0192],\n",
      "        [0.0134, 0.1099, 0.2175, 0.0147, 0.0210],\n",
      "        [0.0017, 0.0767, 0.5458, 0.0466, 0.0690],\n",
      "        [0.0389, 0.8185, 0.0359, 0.9837, 0.0880],\n",
      "        [0.1558, 0.9767, 0.0128, 0.0901, 0.0386],\n",
      "        [0.0183, 0.0408, 0.9828, 0.0363, 0.1062],\n",
      "        [0.0133, 0.9057, 0.0049, 0.4061, 0.1190],\n",
      "        [0.0070, 0.5137, 0.0787, 0.0366, 0.0061],\n",
      "        [0.0969, 0.1241, 0.0997, 0.0230, 0.0382],\n",
      "        [0.0242, 0.3037, 0.1376, 0.9597, 0.0265],\n",
      "        [0.0154, 0.0299, 0.9661, 0.0138, 0.1047],\n",
      "        [0.0208, 0.1361, 0.9124, 0.0177, 0.1067],\n",
      "        [0.0046, 0.0790, 0.8993, 0.0133, 0.2586],\n",
      "        [0.0350, 0.9690, 0.0122, 0.9587, 0.0360],\n",
      "        [0.0105, 0.0972, 0.1605, 0.0432, 0.0108],\n",
      "        [0.0079, 0.7049, 0.0813, 0.0187, 0.0142],\n",
      "        [0.0053, 0.6472, 0.0724, 0.0251, 0.0105],\n",
      "        [0.0572, 0.9833, 0.0104, 0.5703, 0.0128],\n",
      "        [0.0072, 0.1276, 0.9137, 0.0048, 0.3770],\n",
      "        [0.0061, 0.0431, 0.7764, 0.0629, 0.0086],\n",
      "        [0.0044, 0.2538, 0.3200, 0.0929, 0.0212],\n",
      "        [0.0130, 0.9162, 0.0373, 0.0226, 0.9815],\n",
      "        [0.0187, 0.2174, 0.7927, 0.0157, 0.8897],\n",
      "        [0.0080, 0.0268, 0.9270, 0.1289, 0.0297],\n",
      "        [0.5653, 0.9351, 0.0082, 0.5917, 0.9163],\n",
      "        [0.0283, 0.4952, 0.0623, 0.0063, 0.1333],\n",
      "        [0.0133, 0.2171, 0.0334, 0.2309, 0.0385],\n",
      "        [0.0357, 0.9743, 0.0093, 0.5963, 0.0092],\n",
      "        [0.0065, 0.9361, 0.0230, 0.8739, 0.0159],\n",
      "        [0.3766, 0.9656, 0.0061, 0.7400, 0.9462],\n",
      "        [0.1604, 0.9444, 0.0120, 0.1223, 0.0195],\n",
      "        [0.0145, 0.1936, 0.0697, 0.9030, 0.0503],\n",
      "        [0.0309, 0.9881, 0.0148, 0.8267, 0.3184],\n",
      "        [0.0137, 0.2600, 0.0727, 0.0133, 0.0750],\n",
      "        [0.0131, 0.9723, 0.0261, 0.0208, 0.0782],\n",
      "        [0.0057, 0.4676, 0.2557, 0.0054, 0.9464],\n",
      "        [0.0023, 0.5604, 0.1894, 0.0091, 0.4443],\n",
      "        [0.0119, 0.3956, 0.0866, 0.0255, 0.0077],\n",
      "        [0.0166, 0.1809, 0.4428, 0.0295, 0.0050],\n",
      "        [0.0707, 0.1977, 0.0930, 0.9634, 0.1246],\n",
      "        [0.0969, 0.9908, 0.0042, 0.7212, 0.5662]])\n",
      "EXP # =  1  THRESH =  0.35  MICRO F1 =  0.6451612903225806\n",
      "EXP # =  1  THRESH =  0.4  MICRO F1 =  0.65\n",
      "EXP # =  1  THRESH =  0.45  MICRO F1 =  0.6468085106382979\n",
      "EXP # =  1  THRESH =  0.5  MICRO F1 =  0.6523605150214592\n",
      "EXP # =  1  THRESH =  0.55  MICRO F1 =  0.6431718061674009\n",
      "EXP # =  1  THRESH =  0.6  MICRO F1 =  0.6301369863013698\n",
      "EXP # =  1  THRESH =  0.65  MICRO F1 =  0.6232558139534884\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e85cdd7ffda461abc54e9f819249fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBS:  tensor([[0.0717, 0.9421, 0.0219, 0.2301, 0.0155],\n",
      "        [0.0141, 0.7350, 0.0173, 0.7029, 0.0500],\n",
      "        [0.2187, 0.2591, 0.0877, 0.0960, 0.0668],\n",
      "        [0.0470, 0.6432, 0.0942, 0.0485, 0.1017],\n",
      "        [0.1881, 0.9128, 0.0192, 0.9503, 0.5102],\n",
      "        [0.2976, 0.5494, 0.0252, 0.7744, 0.1596],\n",
      "        [0.1086, 0.9729, 0.0092, 0.5887, 0.0372],\n",
      "        [0.0167, 0.2141, 0.2151, 0.8250, 0.0327],\n",
      "        [0.0222, 0.9812, 0.0182, 0.1359, 0.5217],\n",
      "        [0.0068, 0.6533, 0.0598, 0.0201, 0.8728],\n",
      "        [0.0157, 0.9652, 0.0162, 0.3212, 0.0241],\n",
      "        [0.0231, 0.9570, 0.0170, 0.3423, 0.9275],\n",
      "        [0.0639, 0.9851, 0.0096, 0.5094, 0.6571],\n",
      "        [0.0188, 0.9478, 0.0187, 0.0527, 0.8836],\n",
      "        [0.0304, 0.9686, 0.0100, 0.6703, 0.0378],\n",
      "        [0.1720, 0.9847, 0.0107, 0.6227, 0.0787],\n",
      "        [0.1308, 0.9142, 0.0294, 0.0261, 0.4832],\n",
      "        [0.1459, 0.8688, 0.0125, 0.4098, 0.0337],\n",
      "        [0.0294, 0.2046, 0.7135, 0.0102, 0.5749],\n",
      "        [0.1144, 0.5247, 0.0512, 0.7820, 0.0114],\n",
      "        [0.0122, 0.1712, 0.6271, 0.0260, 0.0162],\n",
      "        [0.7119, 0.4169, 0.0368, 0.6906, 0.0847],\n",
      "        [0.0407, 0.9600, 0.0104, 0.8069, 0.0370],\n",
      "        [0.0144, 0.9774, 0.0117, 0.2044, 0.0588],\n",
      "        [0.1490, 0.5405, 0.0339, 0.0749, 0.8160],\n",
      "        [0.0117, 0.0551, 0.5791, 0.0278, 0.4398],\n",
      "        [0.0195, 0.9059, 0.0177, 0.0818, 0.9443],\n",
      "        [0.0542, 0.1169, 0.1547, 0.6629, 0.0645],\n",
      "        [0.2549, 0.9828, 0.0086, 0.3844, 0.1069],\n",
      "        [0.0069, 0.1250, 0.2345, 0.0181, 0.1590],\n",
      "        [0.6765, 0.1087, 0.1782, 0.2449, 0.0879],\n",
      "        [0.0145, 0.9758, 0.0094, 0.1088, 0.1489],\n",
      "        [0.0114, 0.3731, 0.2440, 0.0112, 0.0382],\n",
      "        [0.0309, 0.9609, 0.0100, 0.7457, 0.0382],\n",
      "        [0.0174, 0.3605, 0.3636, 0.0164, 0.0226],\n",
      "        [0.1521, 0.9751, 0.0108, 0.5974, 0.9176],\n",
      "        [0.5013, 0.7939, 0.0151, 0.5540, 0.4207],\n",
      "        [0.0818, 0.3315, 0.0517, 0.5408, 0.0252],\n",
      "        [0.0140, 0.1601, 0.3291, 0.0126, 0.6450],\n",
      "        [0.0250, 0.7476, 0.0161, 0.1324, 0.0326],\n",
      "        [0.0114, 0.6143, 0.0688, 0.1710, 0.0097],\n",
      "        [0.0705, 0.9869, 0.0082, 0.4457, 0.7295],\n",
      "        [0.0295, 0.0398, 0.7430, 0.0953, 0.0367],\n",
      "        [0.1487, 0.5615, 0.0411, 0.6997, 0.0154],\n",
      "        [0.0051, 0.1364, 0.4060, 0.2016, 0.0630],\n",
      "        [0.0521, 0.7694, 0.0429, 0.9651, 0.0645],\n",
      "        [0.1446, 0.9647, 0.0124, 0.1974, 0.0483],\n",
      "        [0.0323, 0.0397, 0.9497, 0.0678, 0.1142],\n",
      "        [0.0054, 0.6187, 0.0371, 0.0421, 0.0969],\n",
      "        [0.0145, 0.8744, 0.0316, 0.1483, 0.0119],\n",
      "        [0.0139, 0.0709, 0.6548, 0.0124, 0.0852],\n",
      "        [0.0383, 0.6435, 0.0539, 0.9534, 0.0415],\n",
      "        [0.0291, 0.0366, 0.8683, 0.0338, 0.0516],\n",
      "        [0.0366, 0.0550, 0.8885, 0.0235, 0.1512],\n",
      "        [0.3591, 0.3438, 0.0751, 0.0664, 0.7152],\n",
      "        [0.0475, 0.9602, 0.0129, 0.9145, 0.0503],\n",
      "        [0.0162, 0.1945, 0.3285, 0.0244, 0.0181],\n",
      "        [0.0221, 0.6299, 0.1156, 0.0263, 0.0283],\n",
      "        [0.0060, 0.5974, 0.0815, 0.0297, 0.0307],\n",
      "        [0.1553, 0.9724, 0.0138, 0.4100, 0.0305],\n",
      "        [0.0161, 0.2433, 0.5548, 0.0066, 0.2376],\n",
      "        [0.0119, 0.5212, 0.1002, 0.0991, 0.0083],\n",
      "        [0.0078, 0.1641, 0.1943, 0.0541, 0.1384],\n",
      "        [0.0264, 0.8771, 0.0425, 0.0490, 0.9728],\n",
      "        [0.0340, 0.1674, 0.8887, 0.0184, 0.6481],\n",
      "        [0.0172, 0.0759, 0.5587, 0.6294, 0.0834],\n",
      "        [0.1802, 0.9740, 0.0073, 0.5089, 0.6248],\n",
      "        [0.0384, 0.4175, 0.2185, 0.0077, 0.1904],\n",
      "        [0.0142, 0.3510, 0.0344, 0.0536, 0.1234],\n",
      "        [0.0325, 0.9668, 0.0128, 0.5296, 0.0212],\n",
      "        [0.0106, 0.8487, 0.0315, 0.5768, 0.0135],\n",
      "        [0.2212, 0.9727, 0.0124, 0.4843, 0.9366],\n",
      "        [0.1383, 0.7958, 0.0203, 0.2534, 0.0197],\n",
      "        [0.0177, 0.2017, 0.1247, 0.7960, 0.0577],\n",
      "        [0.1019, 0.9890, 0.0079, 0.4621, 0.3763],\n",
      "        [0.1101, 0.4809, 0.0286, 0.0767, 0.0924],\n",
      "        [0.0208, 0.9728, 0.0146, 0.0512, 0.1408],\n",
      "        [0.0197, 0.7899, 0.1247, 0.0213, 0.9624],\n",
      "        [0.0220, 0.0666, 0.4824, 0.0245, 0.2336],\n",
      "        [0.0145, 0.4718, 0.1237, 0.0225, 0.0213],\n",
      "        [0.0208, 0.0799, 0.8459, 0.0223, 0.0296],\n",
      "        [0.1337, 0.3149, 0.0866, 0.9450, 0.1153],\n",
      "        [0.3750, 0.9833, 0.0113, 0.6926, 0.8076]])\n",
      "EXP # =  2  THRESH =  0.35  MICRO F1 =  0.6692015209125475\n",
      "EXP # =  2  THRESH =  0.4  MICRO F1 =  0.6666666666666666\n",
      "EXP # =  2  THRESH =  0.45  MICRO F1 =  0.6720647773279352\n",
      "EXP # =  2  THRESH =  0.5  MICRO F1 =  0.6804979253112033\n",
      "EXP # =  2  THRESH =  0.55  MICRO F1 =  0.6608695652173913\n",
      "EXP # =  2  THRESH =  0.6  MICRO F1 =  0.6363636363636364\n",
      "EXP # =  2  THRESH =  0.65  MICRO F1 =  0.5933014354066986\n",
      "2\n",
      "0.6804979253112033\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# get result of training\n",
    "\n",
    "best_model_num = 0\n",
    "best_micro_f1 = 0\n",
    "corresponding_thresh = 0\n",
    "\n",
    "for curr_experiment in range(0, len(experiments)):\n",
    "  predictions = experiments[curr_experiment][\"trainer\"].predict(mini_tokenized_test) # logits\n",
    "  probs = torch.sigmoid(torch.from_numpy(predictions.predictions)) # percentage probabilities\n",
    "  # probs_array = probs.numpy()\n",
    "  # formatted_probs = np.array([[f\"{value:.3f}\" for value in row] for row in probs_array])\n",
    "\n",
    "  print(\"PROBS: \", probs)\n",
    "  # print(\"LABELS: \", torch.tensor(mini_tokenized_test['label'])) # trues\n",
    "  \n",
    "  best_thresh = 0\n",
    "  best_f1_thresh = 0\n",
    "  for thresh in [0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65]:\n",
    "    # binarize predictions\n",
    "    binary_predictions = (probs >= thresh).long()\n",
    "    # print(\"THRESH = \", thresh)\n",
    "\n",
    "    # get F1 scores\n",
    "    curr_f1 = f1_score(y_true=mini_tokenized_test['label'], y_pred=binary_predictions, average='micro')\n",
    "    print(\"EXP # = \", curr_experiment, \" THRESH = \", thresh, \" MICRO F1 = \", curr_f1)\n",
    "    if curr_f1 > best_f1_thresh:\n",
    "      best_thresh = thresh\n",
    "      best_f1_thresh = curr_f1\n",
    "  \n",
    "  if best_f1_thresh > best_micro_f1:\n",
    "    best_model_num = curr_experiment\n",
    "    best_micro_f1 = best_f1_thresh\n",
    "    corresponding_thresh = best_thresh\n",
    "\n",
    "print(best_model_num)\n",
    "print(best_micro_f1)\n",
    "print(corresponding_thresh)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==GRID SEARCH WITH LR = 2 * 10^-5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e677fb9ca8d5431ab6c58b5a3d45191b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0742d9cb68f54c0980fd69cc248720ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4791913330554962, 'eval_runtime': 27.9807, 'eval_samples_per_second': 2.966, 'eval_steps_per_second': 0.393, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447b52e9fd054af0b439973a9f9979fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4399697780609131, 'eval_runtime': 25.9688, 'eval_samples_per_second': 3.196, 'eval_steps_per_second': 0.424, 'epoch': 2.0}\n",
      "{'loss': 0.4444, 'grad_norm': 1.8974618911743164, 'learning_rate': 3.1649831649831652e-06, 'epoch': 2.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc91f039adf43c99b58d5e44a029653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43773651123046875, 'eval_runtime': 29.7281, 'eval_samples_per_second': 2.792, 'eval_steps_per_second': 0.37, 'epoch': 3.0}\n",
      "{'train_runtime': 7400.5657, 'train_samples_per_second': 0.639, 'train_steps_per_second': 0.08, 'train_loss': 0.4274437676375161, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1f53513b3f450c891ec37ae47a5058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/297 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92035060b4244bfe8f07f1e9d612fd69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5045245289802551, 'eval_runtime': 35.2446, 'eval_samples_per_second': 2.355, 'eval_steps_per_second': 0.312, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb20c78bc334463c9b164c65c17d71c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.46253591775894165, 'eval_runtime': 28.6222, 'eval_samples_per_second': 2.9, 'eval_steps_per_second': 0.384, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f36e919beb4d999fe68d9781fbf2ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45426255464553833, 'eval_runtime': 27.0435, 'eval_samples_per_second': 3.069, 'eval_steps_per_second': 0.407, 'epoch': 3.0}\n",
      "{'train_runtime': 8756.3593, 'train_samples_per_second': 0.54, 'train_steps_per_second': 0.034, 'train_loss': 0.4681395456847117, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072c892888444e44a07a390b8fed5740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd40df73f67f43be89c2d652d65e5c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5429951548576355, 'eval_runtime': 36.8855, 'eval_samples_per_second': 2.25, 'eval_steps_per_second': 0.298, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8f838bdad941c5bcf77937cc2c8ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.499714732170105, 'eval_runtime': 29.0318, 'eval_samples_per_second': 2.859, 'eval_steps_per_second': 0.379, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7956cbb1f63b4fc6a2851feaafc8e8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.48618993163108826, 'eval_runtime': 29.0591, 'eval_samples_per_second': 2.856, 'eval_steps_per_second': 0.379, 'epoch': 3.0}\n",
      "{'train_runtime': 7825.3774, 'train_samples_per_second': 0.605, 'train_steps_per_second': 0.019, 'train_loss': 0.5212098693847657, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# learning_rates = [2e-4, 2e-5, 2e-6]\n",
    "learning_rates = [2e-5]\n",
    "batch_sizes = [8, 16, 32]\n",
    "\n",
    "trial_num = 3\n",
    "for curr_learning_rate in learning_rates:\n",
    "  for curr_batch_size in batch_sizes:\n",
    "    experiments[trial_num] = {}\n",
    "    experiments[trial_num][\"model\"] = AutoModelForSequenceClassification.from_pretrained(model_name, problem_type=\"multi_label_classification\", num_labels=5)\n",
    "    experiments[trial_num][\"training_args\"] = TrainingArguments(output_dir=\"test_trainer\", \n",
    "                                                                eval_strategy=\"epoch\", \n",
    "                                                                per_device_train_batch_size=curr_batch_size, \n",
    "                                                                learning_rate=curr_learning_rate)\n",
    "    experiments[trial_num][\"trainer\"] = Trainer(model=experiments[trial_num][\"model\"], \n",
    "                                                args=experiments[trial_num][\"training_args\"], \n",
    "                                                train_dataset=mini_tokenized_train, \n",
    "                                                eval_dataset=mini_tokenized_test)\n",
    "    experiments[trial_num][\"trainer\"].train()\n",
    "    \n",
    "    trial_num = trial_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd6baa07c6e43dbbcd4677b352ec4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBS:  tensor([[0.1434, 0.8233, 0.0766, 0.6052, 0.0796],\n",
      "        [0.0552, 0.8195, 0.0595, 0.3662, 0.1998],\n",
      "        [0.1605, 0.4852, 0.1217, 0.3269, 0.1244],\n",
      "        [0.0636, 0.4181, 0.2154, 0.1473, 0.2981],\n",
      "        [0.2363, 0.8905, 0.0671, 0.7903, 0.3087],\n",
      "        [0.1251, 0.6978, 0.0627, 0.4021, 0.3901],\n",
      "        [0.1242, 0.8195, 0.0624, 0.5033, 0.0793],\n",
      "        [0.0836, 0.6713, 0.1260, 0.6820, 0.0656],\n",
      "        [0.2079, 0.9079, 0.0611, 0.4078, 0.6759],\n",
      "        [0.0489, 0.8432, 0.0620, 0.2079, 0.3983],\n",
      "        [0.0708, 0.8544, 0.0824, 0.4543, 0.0712],\n",
      "        [0.0873, 0.8693, 0.0894, 0.2474, 0.7711],\n",
      "        [0.1879, 0.7886, 0.1009, 0.2412, 0.7248],\n",
      "        [0.1607, 0.8834, 0.0599, 0.2415, 0.7860],\n",
      "        [0.0960, 0.8706, 0.0739, 0.6072, 0.0949],\n",
      "        [0.3577, 0.9087, 0.0641, 0.7125, 0.2383],\n",
      "        [0.1594, 0.8533, 0.0616, 0.1537, 0.6558],\n",
      "        [0.1227, 0.8690, 0.0469, 0.5012, 0.1372],\n",
      "        [0.0827, 0.2230, 0.5471, 0.0662, 0.5536],\n",
      "        [0.2730, 0.7415, 0.1116, 0.7790, 0.0727],\n",
      "        [0.0594, 0.1975, 0.5927, 0.2029, 0.0527],\n",
      "        [0.2038, 0.2918, 0.1759, 0.2296, 0.1905],\n",
      "        [0.1339, 0.8748, 0.0637, 0.6389, 0.1118],\n",
      "        [0.0766, 0.8951, 0.0605, 0.4179, 0.1159],\n",
      "        [0.0707, 0.4446, 0.2095, 0.0859, 0.6667],\n",
      "        [0.0546, 0.1354, 0.5694, 0.0993, 0.2517],\n",
      "        [0.1199, 0.8875, 0.0623, 0.2112, 0.8085],\n",
      "        [0.1090, 0.4101, 0.1778, 0.1989, 0.2726],\n",
      "        [0.2071, 0.9064, 0.0495, 0.6040, 0.1253],\n",
      "        [0.0516, 0.3356, 0.2168, 0.1409, 0.1007],\n",
      "        [0.1890, 0.3939, 0.1574, 0.1175, 0.4065],\n",
      "        [0.1199, 0.9221, 0.0437, 0.4446, 0.3366],\n",
      "        [0.0572, 0.2213, 0.4674, 0.0865, 0.0792],\n",
      "        [0.1528, 0.9210, 0.0517, 0.6894, 0.1636],\n",
      "        [0.0517, 0.3006, 0.3668, 0.0848, 0.0946],\n",
      "        [0.2208, 0.9300, 0.0508, 0.4730, 0.6941],\n",
      "        [0.3427, 0.7946, 0.0642, 0.5374, 0.2557],\n",
      "        [0.1673, 0.5581, 0.1417, 0.4637, 0.0684],\n",
      "        [0.0617, 0.2229, 0.5180, 0.0564, 0.4854],\n",
      "        [0.1265, 0.6709, 0.0625, 0.2831, 0.1141],\n",
      "        [0.0481, 0.4462, 0.2775, 0.2594, 0.0463],\n",
      "        [0.2049, 0.9383, 0.0462, 0.4980, 0.5203],\n",
      "        [0.0458, 0.4285, 0.2941, 0.1434, 0.1521],\n",
      "        [0.0655, 0.2354, 0.3793, 0.1107, 0.0712],\n",
      "        [0.0546, 0.7820, 0.1080, 0.5406, 0.1221],\n",
      "        [0.0957, 0.7846, 0.1043, 0.6989, 0.0855],\n",
      "        [0.0705, 0.6725, 0.0987, 0.2644, 0.0834],\n",
      "        [0.1206, 0.1470, 0.8241, 0.1705, 0.3074],\n",
      "        [0.1355, 0.8965, 0.0466, 0.5546, 0.1511],\n",
      "        [0.0557, 0.7047, 0.1080, 0.2388, 0.0587],\n",
      "        [0.0540, 0.1702, 0.5397, 0.0692, 0.1442],\n",
      "        [0.1367, 0.6899, 0.1384, 0.7787, 0.0565],\n",
      "        [0.1036, 0.1192, 0.7553, 0.1093, 0.2170],\n",
      "        [0.1192, 0.2314, 0.4362, 0.0950, 0.3056],\n",
      "        [0.0863, 0.2297, 0.4918, 0.0562, 0.4773],\n",
      "        [0.1226, 0.8981, 0.0669, 0.7106, 0.0845],\n",
      "        [0.0585, 0.2633, 0.3864, 0.1030, 0.0664],\n",
      "        [0.0499, 0.4181, 0.2281, 0.0707, 0.2441],\n",
      "        [0.0394, 0.4449, 0.2828, 0.1584, 0.0598],\n",
      "        [0.0742, 0.7767, 0.0799, 0.3344, 0.0907],\n",
      "        [0.0589, 0.2803, 0.4732, 0.0495, 0.5202],\n",
      "        [0.0486, 0.3530, 0.3169, 0.1895, 0.0403],\n",
      "        [0.0618, 0.4973, 0.1475, 0.2032, 0.2113],\n",
      "        [0.1179, 0.8228, 0.1156, 0.1689, 0.8764],\n",
      "        [0.0846, 0.2046, 0.6626, 0.0935, 0.3242],\n",
      "        [0.0684, 0.3264, 0.3759, 0.5061, 0.1099],\n",
      "        [0.2170, 0.9120, 0.0449, 0.5091, 0.3693],\n",
      "        [0.0609, 0.4618, 0.1846, 0.0651, 0.2528],\n",
      "        [0.0800, 0.5664, 0.0852, 0.2383, 0.1994],\n",
      "        [0.0995, 0.8765, 0.0575, 0.5800, 0.0887],\n",
      "        [0.0577, 0.8039, 0.0809, 0.4926, 0.0821],\n",
      "        [0.2103, 0.9114, 0.0678, 0.2769, 0.8306],\n",
      "        [0.1956, 0.7126, 0.0668, 0.5170, 0.0956],\n",
      "        [0.1957, 0.8483, 0.0577, 0.7130, 0.1358],\n",
      "        [0.1779, 0.8288, 0.0893, 0.5120, 0.2639],\n",
      "        [0.1052, 0.7551, 0.0598, 0.1764, 0.2266],\n",
      "        [0.1110, 0.9153, 0.0461, 0.2942, 0.2893],\n",
      "        [0.0988, 0.7428, 0.1316, 0.0871, 0.8245],\n",
      "        [0.0767, 0.4183, 0.2276, 0.0847, 0.4120],\n",
      "        [0.0518, 0.4430, 0.2253, 0.1447, 0.0630],\n",
      "        [0.0735, 0.1711, 0.5390, 0.0975, 0.1140],\n",
      "        [0.2489, 0.6890, 0.1499, 0.8137, 0.1688],\n",
      "        [0.2957, 0.9404, 0.0547, 0.5217, 0.6029]])\n",
      "EXP # =  3  THRESH =  0.35  MICRO F1 =  0.6914498141263941\n",
      "EXP # =  3  THRESH =  0.4  MICRO F1 =  0.6744186046511628\n",
      "EXP # =  3  THRESH =  0.45  MICRO F1 =  0.6446280991735537\n",
      "EXP # =  3  THRESH =  0.5  MICRO F1 =  0.6200873362445415\n",
      "EXP # =  3  THRESH =  0.55  MICRO F1 =  0.5794392523364486\n",
      "EXP # =  3  THRESH =  0.6  MICRO F1 =  0.5507246376811594\n",
      "EXP # =  3  THRESH =  0.65  MICRO F1 =  0.5445544554455446\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941e39c606f841efb11dea038532dcfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBS:  tensor([[0.2039, 0.7671, 0.1180, 0.5209, 0.1394],\n",
      "        [0.0974, 0.8024, 0.0873, 0.3069, 0.3292],\n",
      "        [0.1050, 0.4825, 0.1635, 0.2422, 0.2217],\n",
      "        [0.1030, 0.5253, 0.1967, 0.2652, 0.1938],\n",
      "        [0.2851, 0.8547, 0.0838, 0.6644, 0.4305],\n",
      "        [0.1852, 0.6774, 0.0987, 0.2816, 0.5254],\n",
      "        [0.1367, 0.7999, 0.0868, 0.4148, 0.2011],\n",
      "        [0.0736, 0.4859, 0.2365, 0.3497, 0.1650],\n",
      "        [0.2281, 0.8577, 0.1059, 0.3911, 0.6547],\n",
      "        [0.0558, 0.7444, 0.1352, 0.1671, 0.3979],\n",
      "        [0.0921, 0.7808, 0.1274, 0.3983, 0.1505],\n",
      "        [0.0770, 0.8208, 0.1180, 0.2591, 0.4792],\n",
      "        [0.2253, 0.8101, 0.0917, 0.3463, 0.6289],\n",
      "        [0.1764, 0.8471, 0.1084, 0.2587, 0.7064],\n",
      "        [0.1250, 0.8086, 0.0983, 0.5395, 0.2120],\n",
      "        [0.2698, 0.8698, 0.0837, 0.6393, 0.2489],\n",
      "        [0.1634, 0.8431, 0.0740, 0.2645, 0.5388],\n",
      "        [0.0971, 0.7841, 0.1045, 0.3647, 0.1896],\n",
      "        [0.1187, 0.2801, 0.5570, 0.1094, 0.4340],\n",
      "        [0.3292, 0.7465, 0.1202, 0.7239, 0.1632],\n",
      "        [0.1022, 0.2807, 0.4821, 0.2943, 0.1082],\n",
      "        [0.1720, 0.3387, 0.1986, 0.2288, 0.3701],\n",
      "        [0.1553, 0.8098, 0.1049, 0.5814, 0.1629],\n",
      "        [0.1013, 0.8613, 0.0883, 0.4081, 0.2481],\n",
      "        [0.0968, 0.4346, 0.3034, 0.1179, 0.5974],\n",
      "        [0.0762, 0.2527, 0.4695, 0.1402, 0.3646],\n",
      "        [0.1302, 0.8464, 0.0969, 0.2403, 0.6554],\n",
      "        [0.0984, 0.4440, 0.1882, 0.2644, 0.2882],\n",
      "        [0.2235, 0.8480, 0.0852, 0.6256, 0.1721],\n",
      "        [0.0604, 0.4878, 0.2050, 0.1699, 0.2543],\n",
      "        [0.1378, 0.4306, 0.1928, 0.1856, 0.4639],\n",
      "        [0.1279, 0.8870, 0.0743, 0.3897, 0.3722],\n",
      "        [0.0946, 0.2378, 0.5444, 0.1336, 0.1536],\n",
      "        [0.1948, 0.8749, 0.0774, 0.6440, 0.2248],\n",
      "        [0.0678, 0.4877, 0.2982, 0.1363, 0.1952],\n",
      "        [0.2679, 0.8912, 0.0810, 0.4972, 0.5721],\n",
      "        [0.3894, 0.7916, 0.0826, 0.5778, 0.3982],\n",
      "        [0.2249, 0.5899, 0.1633, 0.4119, 0.1963],\n",
      "        [0.0942, 0.2495, 0.5183, 0.0931, 0.4734],\n",
      "        [0.1147, 0.7619, 0.0843, 0.3864, 0.1986],\n",
      "        [0.0782, 0.3735, 0.3815, 0.2449, 0.1265],\n",
      "        [0.1894, 0.8882, 0.0789, 0.3819, 0.5450],\n",
      "        [0.0646, 0.4234, 0.3108, 0.1296, 0.3615],\n",
      "        [0.0919, 0.2352, 0.4855, 0.1537, 0.1760],\n",
      "        [0.0622, 0.4096, 0.3016, 0.2385, 0.2236],\n",
      "        [0.1321, 0.6955, 0.1590, 0.5392, 0.1137],\n",
      "        [0.0787, 0.6107, 0.1862, 0.2642, 0.1328],\n",
      "        [0.1262, 0.1724, 0.6821, 0.1664, 0.3233],\n",
      "        [0.0983, 0.7384, 0.1055, 0.3856, 0.1738],\n",
      "        [0.1041, 0.7752, 0.1113, 0.3501, 0.1465],\n",
      "        [0.0632, 0.2695, 0.4726, 0.0987, 0.2663],\n",
      "        [0.1777, 0.5378, 0.2216, 0.6523, 0.1146],\n",
      "        [0.1206, 0.1634, 0.6827, 0.1340, 0.3067],\n",
      "        [0.1034, 0.3207, 0.4048, 0.1313, 0.3671],\n",
      "        [0.1082, 0.1998, 0.5950, 0.1084, 0.4400],\n",
      "        [0.1730, 0.8685, 0.0851, 0.6154, 0.2039],\n",
      "        [0.0835, 0.2592, 0.4586, 0.1342, 0.1568],\n",
      "        [0.0649, 0.4488, 0.2775, 0.1296, 0.4403],\n",
      "        [0.0606, 0.3925, 0.3583, 0.1570, 0.1545],\n",
      "        [0.0722, 0.5849, 0.2160, 0.1962, 0.1624],\n",
      "        [0.0787, 0.3635, 0.4366, 0.0791, 0.4714],\n",
      "        [0.0758, 0.3255, 0.4110, 0.2182, 0.1166],\n",
      "        [0.0735, 0.6026, 0.1780, 0.2854, 0.1713],\n",
      "        [0.1306, 0.7278, 0.1721, 0.1505, 0.7777],\n",
      "        [0.1333, 0.2112, 0.5915, 0.1319, 0.3280],\n",
      "        [0.0860, 0.3601, 0.3489, 0.3437, 0.2010],\n",
      "        [0.2887, 0.8627, 0.0690, 0.5443, 0.4231],\n",
      "        [0.0660, 0.4495, 0.2829, 0.0980, 0.3903],\n",
      "        [0.0961, 0.6781, 0.1033, 0.2922, 0.3113],\n",
      "        [0.1513, 0.8360, 0.0943, 0.5626, 0.1500],\n",
      "        [0.0925, 0.7711, 0.1147, 0.4321, 0.1482],\n",
      "        [0.2673, 0.8779, 0.0839, 0.4036, 0.6699],\n",
      "        [0.1729, 0.7535, 0.0857, 0.4980, 0.2254],\n",
      "        [0.2279, 0.7986, 0.0704, 0.5843, 0.2958],\n",
      "        [0.1715, 0.7906, 0.1149, 0.4609, 0.3008],\n",
      "        [0.1079, 0.7274, 0.0984, 0.2636, 0.2994],\n",
      "        [0.1236, 0.8781, 0.0720, 0.3229, 0.3393],\n",
      "        [0.1122, 0.7505, 0.1494, 0.1372, 0.7047],\n",
      "        [0.0845, 0.4262, 0.3283, 0.1012, 0.6208],\n",
      "        [0.0911, 0.4585, 0.2817, 0.1455, 0.1780],\n",
      "        [0.1029, 0.2076, 0.6204, 0.1255, 0.2568],\n",
      "        [0.3040, 0.7359, 0.0930, 0.6607, 0.3311],\n",
      "        [0.3027, 0.8998, 0.0766, 0.5038, 0.5463]])\n",
      "EXP # =  4  THRESH =  0.35  MICRO F1 =  0.6714285714285714\n",
      "EXP # =  4  THRESH =  0.4  MICRO F1 =  0.6381322957198443\n",
      "EXP # =  4  THRESH =  0.45  MICRO F1 =  0.6016949152542372\n",
      "EXP # =  4  THRESH =  0.5  MICRO F1 =  0.5570776255707762\n",
      "EXP # =  4  THRESH =  0.55  MICRO F1 =  0.5339805825242718\n",
      "EXP # =  4  THRESH =  0.6  MICRO F1 =  0.5025641025641026\n",
      "EXP # =  4  THRESH =  0.65  MICRO F1 =  0.4838709677419355\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b7fcddc61e4f6cac284dc4417acf14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBS:  tensor([[0.2067, 0.7522, 0.1527, 0.4525, 0.2373],\n",
      "        [0.1396, 0.7499, 0.1307, 0.3477, 0.3419],\n",
      "        [0.1104, 0.5245, 0.2116, 0.2377, 0.3083],\n",
      "        [0.1734, 0.7178, 0.1428, 0.3874, 0.2989],\n",
      "        [0.2739, 0.7813, 0.1382, 0.5510, 0.4676],\n",
      "        [0.2013, 0.6790, 0.1423, 0.3350, 0.4894],\n",
      "        [0.1554, 0.7661, 0.1248, 0.3932, 0.2863],\n",
      "        [0.0999, 0.6064, 0.2000, 0.3034, 0.2756],\n",
      "        [0.2593, 0.7786, 0.1628, 0.4612, 0.5173],\n",
      "        [0.1069, 0.7202, 0.1483, 0.2789, 0.3541],\n",
      "        [0.1624, 0.7949, 0.1412, 0.4504, 0.2544],\n",
      "        [0.1153, 0.7527, 0.1570, 0.3639, 0.3350],\n",
      "        [0.2318, 0.7543, 0.1299, 0.4099, 0.4992],\n",
      "        [0.2141, 0.7785, 0.1515, 0.3841, 0.5325],\n",
      "        [0.1560, 0.7728, 0.1359, 0.4626, 0.3293],\n",
      "        [0.2281, 0.8010, 0.1287, 0.5122, 0.3228],\n",
      "        [0.1796, 0.7873, 0.1181, 0.3711, 0.4248],\n",
      "        [0.1335, 0.7502, 0.1486, 0.3762, 0.2532],\n",
      "        [0.1539, 0.3494, 0.4985, 0.1861, 0.3888],\n",
      "        [0.2516, 0.7611, 0.1382, 0.5393, 0.2836],\n",
      "        [0.1154, 0.4049, 0.3975, 0.2558, 0.1978],\n",
      "        [0.1557, 0.5780, 0.1571, 0.2855, 0.4173],\n",
      "        [0.1745, 0.7818, 0.1428, 0.4986, 0.2497],\n",
      "        [0.1628, 0.8087, 0.1316, 0.4525, 0.3099],\n",
      "        [0.1360, 0.5264, 0.2673, 0.2291, 0.5005],\n",
      "        [0.1149, 0.3608, 0.4000, 0.2018, 0.3775],\n",
      "        [0.1729, 0.7799, 0.1390, 0.3500, 0.4947],\n",
      "        [0.1074, 0.5127, 0.2352, 0.2447, 0.3765],\n",
      "        [0.2206, 0.8106, 0.1243, 0.5207, 0.2745],\n",
      "        [0.0988, 0.5292, 0.2396, 0.2157, 0.3269],\n",
      "        [0.1378, 0.5064, 0.2250, 0.2343, 0.4719],\n",
      "        [0.1742, 0.8171, 0.1186, 0.4344, 0.3655],\n",
      "        [0.1296, 0.3501, 0.4431, 0.1854, 0.2139],\n",
      "        [0.2216, 0.8150, 0.1173, 0.5420, 0.3054],\n",
      "        [0.1127, 0.5554, 0.2780, 0.2173, 0.2306],\n",
      "        [0.2534, 0.8134, 0.1299, 0.4914, 0.4809],\n",
      "        [0.2944, 0.7548, 0.1303, 0.4938, 0.4391],\n",
      "        [0.1712, 0.5991, 0.2040, 0.3421, 0.2706],\n",
      "        [0.1259, 0.3326, 0.4538, 0.1628, 0.4104],\n",
      "        [0.1703, 0.7761, 0.1173, 0.4344, 0.3205],\n",
      "        [0.1123, 0.4238, 0.3977, 0.2194, 0.2289],\n",
      "        [0.2091, 0.8168, 0.1271, 0.4313, 0.4216],\n",
      "        [0.1063, 0.4502, 0.3278, 0.1884, 0.3690],\n",
      "        [0.1289, 0.3532, 0.4195, 0.1988, 0.2568],\n",
      "        [0.1082, 0.5347, 0.2442, 0.2890, 0.3316],\n",
      "        [0.1620, 0.7352, 0.1587, 0.4513, 0.2273],\n",
      "        [0.1059, 0.5604, 0.2433, 0.2570, 0.2054],\n",
      "        [0.1575, 0.2929, 0.5518, 0.2133, 0.3812],\n",
      "        [0.1390, 0.7555, 0.1301, 0.3952, 0.2685],\n",
      "        [0.1459, 0.7338, 0.1457, 0.3445, 0.2486],\n",
      "        [0.0962, 0.3869, 0.4014, 0.1627, 0.3077],\n",
      "        [0.1504, 0.6614, 0.1791, 0.4771, 0.2328],\n",
      "        [0.1460, 0.2785, 0.5529, 0.1825, 0.3773],\n",
      "        [0.1053, 0.5309, 0.2626, 0.2181, 0.3597],\n",
      "        [0.1288, 0.3140, 0.4793, 0.1844, 0.4215],\n",
      "        [0.2225, 0.8181, 0.1245, 0.5422, 0.3239],\n",
      "        [0.1237, 0.3492, 0.4366, 0.1782, 0.2422],\n",
      "        [0.1070, 0.4230, 0.3469, 0.1895, 0.4221],\n",
      "        [0.1004, 0.5178, 0.2669, 0.2278, 0.2155],\n",
      "        [0.1024, 0.5400, 0.2677, 0.2110, 0.2272],\n",
      "        [0.1204, 0.3826, 0.4203, 0.1528, 0.3736],\n",
      "        [0.1044, 0.3918, 0.3987, 0.2052, 0.2076],\n",
      "        [0.1136, 0.6300, 0.1962, 0.3149, 0.2483],\n",
      "        [0.1534, 0.6763, 0.1928, 0.2560, 0.5910],\n",
      "        [0.1723, 0.3405, 0.4458, 0.1927, 0.3624],\n",
      "        [0.1168, 0.5738, 0.2371, 0.3551, 0.3214],\n",
      "        [0.2667, 0.7881, 0.1192, 0.5089, 0.4061],\n",
      "        [0.1010, 0.4287, 0.3525, 0.1696, 0.3430],\n",
      "        [0.1312, 0.7044, 0.1446, 0.3218, 0.3731],\n",
      "        [0.1870, 0.8021, 0.1312, 0.4883, 0.2480],\n",
      "        [0.1410, 0.7686, 0.1398, 0.4137, 0.2468],\n",
      "        [0.2716, 0.7986, 0.1371, 0.4523, 0.5263],\n",
      "        [0.1507, 0.7191, 0.1295, 0.3879, 0.3284],\n",
      "        [0.2104, 0.7688, 0.1136, 0.4581, 0.4238],\n",
      "        [0.1691, 0.7337, 0.1649, 0.4182, 0.3402],\n",
      "        [0.1507, 0.7371, 0.1292, 0.3586, 0.3202],\n",
      "        [0.1247, 0.7671, 0.1355, 0.3246, 0.2933],\n",
      "        [0.1271, 0.6975, 0.1734, 0.2476, 0.5148],\n",
      "        [0.1208, 0.4618, 0.3030, 0.1931, 0.5121],\n",
      "        [0.1338, 0.4964, 0.2784, 0.1944, 0.2528],\n",
      "        [0.1158, 0.3528, 0.4639, 0.1814, 0.3116],\n",
      "        [0.2531, 0.7524, 0.1268, 0.4933, 0.4822],\n",
      "        [0.2759, 0.8221, 0.1298, 0.4999, 0.4364]])\n",
      "EXP # =  5  THRESH =  0.35  MICRO F1 =  0.6577181208053692\n",
      "EXP # =  5  THRESH =  0.4  MICRO F1 =  0.6159695817490495\n",
      "EXP # =  5  THRESH =  0.45  MICRO F1 =  0.5654008438818565\n",
      "EXP # =  5  THRESH =  0.5  MICRO F1 =  0.5096153846153846\n",
      "EXP # =  5  THRESH =  0.55  MICRO F1 =  0.4385026737967914\n",
      "EXP # =  5  THRESH =  0.6  MICRO F1 =  0.38202247191011235\n",
      "EXP # =  5  THRESH =  0.65  MICRO F1 =  0.38636363636363635\n",
      "3\n",
      "0.6914498141263941\n",
      "0.35\n"
     ]
    }
   ],
   "source": [
    "# evaluate performance\n",
    "best_model_num = 0\n",
    "best_micro_f1 = 0\n",
    "corresponding_thresh = 0\n",
    "\n",
    "for curr_experiment in [3, 4, 5]:\n",
    "  predictions = experiments[curr_experiment][\"trainer\"].predict(mini_tokenized_test) # logits\n",
    "  probs = torch.sigmoid(torch.from_numpy(predictions.predictions)) # percentage probabilities\n",
    "  # probs_array = probs.numpy()\n",
    "  # formatted_probs = np.array([[f\"{value:.3f}\" for value in row] for row in probs_array])\n",
    "\n",
    "  print(\"PROBS: \", probs)\n",
    "  # print(\"LABELS: \", torch.tensor(mini_tokenized_test['label'])) # trues\n",
    "  \n",
    "  best_thresh = 0\n",
    "  best_f1_thresh = 0\n",
    "  for thresh in [0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65]:\n",
    "    # binarize predictions\n",
    "    binary_predictions = (probs >= thresh).long()\n",
    "    # print(\"THRESH = \", thresh)\n",
    "\n",
    "    # get F1 scores\n",
    "    curr_f1 = f1_score(y_true=mini_tokenized_test['label'], y_pred=binary_predictions, average='micro')\n",
    "    print(\"EXP # = \", curr_experiment, \" THRESH = \", thresh, \" MICRO F1 = \", curr_f1)\n",
    "    if curr_f1 > best_f1_thresh:\n",
    "      best_thresh = thresh\n",
    "      best_f1_thresh = curr_f1\n",
    "  \n",
    "  if best_f1_thresh > best_micro_f1:\n",
    "    best_model_num = curr_experiment\n",
    "    best_micro_f1 = best_f1_thresh\n",
    "    corresponding_thresh = best_thresh\n",
    "\n",
    "print(best_model_num)\n",
    "print(best_micro_f1)\n",
    "print(corresponding_thresh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==GRID SEARCH WITH LEARNING_RATE = 2*10^-6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54dd92e96b064dd7824bdda130219721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34eab61abf344c2ca0eb1671b70a67d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5868320465087891, 'eval_runtime': 26.6023, 'eval_samples_per_second': 3.12, 'eval_steps_per_second': 0.413, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4202bdea3340998f3af5e9236bc693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5630336999893188, 'eval_runtime': 24.1094, 'eval_samples_per_second': 3.443, 'eval_steps_per_second': 0.456, 'epoch': 2.0}\n",
      "{'loss': 0.595, 'grad_norm': 1.053056240081787, 'learning_rate': 3.164983164983165e-07, 'epoch': 2.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ce124538714d90bfeb719cc9284905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5594221353530884, 'eval_runtime': 33.4727, 'eval_samples_per_second': 2.48, 'eval_steps_per_second': 0.329, 'epoch': 3.0}\n",
      "{'train_runtime': 7801.099, 'train_samples_per_second': 0.606, 'train_steps_per_second': 0.076, 'train_loss': 0.5889468787093757, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3913d83526dd4dbda80b2ce042c5d7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/297 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3834430f7372451da66fc0c4c2847970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6307984590530396, 'eval_runtime': 44.7968, 'eval_samples_per_second': 1.853, 'eval_steps_per_second': 0.246, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30eabbf3c9214d24af3cad71b4e27774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5936164259910583, 'eval_runtime': 31.1337, 'eval_samples_per_second': 2.666, 'eval_steps_per_second': 0.353, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c3e8919013433f9c299ad5154c8c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5865357518196106, 'eval_runtime': 31.8827, 'eval_samples_per_second': 2.603, 'eval_steps_per_second': 0.345, 'epoch': 3.0}\n",
      "{'train_runtime': 9296.0052, 'train_samples_per_second': 0.509, 'train_steps_per_second': 0.032, 'train_loss': 0.6210316359394729, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0921e513db54ab48d2e9f4472242185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57dfcefff774eaa947920ed3a9ac0c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6702682375907898, 'eval_runtime': 32.0827, 'eval_samples_per_second': 2.587, 'eval_steps_per_second': 0.343, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ee38dccf704133b97b66c910f15b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6390492916107178, 'eval_runtime': 30.4813, 'eval_samples_per_second': 2.723, 'eval_steps_per_second': 0.361, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2977066f17496984f4a616c8df38c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6288503408432007, 'eval_runtime': 27.7189, 'eval_samples_per_second': 2.994, 'eval_steps_per_second': 0.397, 'epoch': 3.0}\n",
      "{'train_runtime': 8123.404, 'train_samples_per_second': 0.582, 'train_steps_per_second': 0.018, 'train_loss': 0.6576084391276041, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# learning_rates = [2e-4, 2e-5, 2e-6]\n",
    "learning_rates = [2e-6]\n",
    "batch_sizes = [8, 16, 32]\n",
    "\n",
    "trial_num = 6\n",
    "for curr_learning_rate in learning_rates:\n",
    "  for curr_batch_size in batch_sizes:\n",
    "    experiments[trial_num] = {}\n",
    "    experiments[trial_num][\"model\"] = AutoModelForSequenceClassification.from_pretrained(model_name, problem_type=\"multi_label_classification\", num_labels=5)\n",
    "    experiments[trial_num][\"training_args\"] = TrainingArguments(output_dir=\"test_trainer\", \n",
    "                                                                eval_strategy=\"epoch\", \n",
    "                                                                per_device_train_batch_size=curr_batch_size, \n",
    "                                                                learning_rate=curr_learning_rate)\n",
    "    experiments[trial_num][\"trainer\"] = Trainer(model=experiments[trial_num][\"model\"], \n",
    "                                                args=experiments[trial_num][\"training_args\"], \n",
    "                                                train_dataset=mini_tokenized_train, \n",
    "                                                eval_dataset=mini_tokenized_test)\n",
    "    experiments[trial_num][\"trainer\"].train()\n",
    "    \n",
    "    trial_num = trial_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9ad3480d1040f3b1359e41a856b3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBS:  tensor([[0.1803, 0.6061, 0.2533, 0.3577, 0.3242],\n",
      "        [0.1638, 0.5714, 0.2529, 0.3321, 0.3181],\n",
      "        [0.1768, 0.5429, 0.2897, 0.3304, 0.3204],\n",
      "        [0.1598, 0.5870, 0.2587, 0.3449, 0.3086],\n",
      "        [0.1863, 0.5520, 0.2737, 0.3716, 0.3303],\n",
      "        [0.1822, 0.5301, 0.2715, 0.3468, 0.3456],\n",
      "        [0.1775, 0.5589, 0.2765, 0.3490, 0.3152],\n",
      "        [0.1658, 0.5848, 0.2802, 0.3317, 0.3056],\n",
      "        [0.1928, 0.5753, 0.2656, 0.3507, 0.3417],\n",
      "        [0.1629, 0.5997, 0.2423, 0.3450, 0.2905],\n",
      "        [0.1751, 0.6060, 0.2831, 0.3433, 0.2844],\n",
      "        [0.1612, 0.5941, 0.2719, 0.3470, 0.3228],\n",
      "        [0.1903, 0.5474, 0.2805, 0.3749, 0.3266],\n",
      "        [0.2114, 0.5200, 0.2915, 0.3283, 0.3716],\n",
      "        [0.2295, 0.5357, 0.3121, 0.3657, 0.3480],\n",
      "        [0.1687, 0.5898, 0.2777, 0.3541, 0.3156],\n",
      "        [0.1701, 0.5799, 0.2616, 0.3461, 0.3072],\n",
      "        [0.1657, 0.5905, 0.2529, 0.3296, 0.3005],\n",
      "        [0.2001, 0.5308, 0.3227, 0.3586, 0.3328],\n",
      "        [0.1755, 0.5750, 0.2646, 0.3533, 0.3213],\n",
      "        [0.1588, 0.5541, 0.2825, 0.3501, 0.2828],\n",
      "        [0.1689, 0.5485, 0.2542, 0.3331, 0.3253],\n",
      "        [0.1881, 0.5620, 0.2890, 0.3538, 0.3069],\n",
      "        [0.1719, 0.6124, 0.2656, 0.3356, 0.2852],\n",
      "        [0.1872, 0.5454, 0.2712, 0.3585, 0.3222],\n",
      "        [0.1990, 0.5176, 0.3045, 0.3211, 0.3248],\n",
      "        [0.1744, 0.5648, 0.2502, 0.3313, 0.3109],\n",
      "        [0.1838, 0.5328, 0.3109, 0.3548, 0.3313],\n",
      "        [0.1650, 0.6086, 0.2533, 0.3435, 0.2782],\n",
      "        [0.1672, 0.5637, 0.2853, 0.3391, 0.3212],\n",
      "        [0.1946, 0.5319, 0.2639, 0.3320, 0.3312],\n",
      "        [0.1727, 0.6127, 0.2675, 0.3596, 0.3007],\n",
      "        [0.1741, 0.5555, 0.2625, 0.3316, 0.3049],\n",
      "        [0.1617, 0.6105, 0.2554, 0.3491, 0.2950],\n",
      "        [0.1684, 0.6056, 0.2552, 0.3201, 0.2976],\n",
      "        [0.1690, 0.5962, 0.2597, 0.3258, 0.3152],\n",
      "        [0.2017, 0.5392, 0.2745, 0.3529, 0.3470],\n",
      "        [0.1903, 0.5939, 0.2791, 0.3554, 0.2980],\n",
      "        [0.1927, 0.5296, 0.2883, 0.3124, 0.3291],\n",
      "        [0.1633, 0.5865, 0.2448, 0.3364, 0.3077],\n",
      "        [0.1616, 0.5676, 0.2746, 0.3311, 0.2917],\n",
      "        [0.1712, 0.5847, 0.2777, 0.3490, 0.2915],\n",
      "        [0.1856, 0.5577, 0.3150, 0.3713, 0.2983],\n",
      "        [0.1972, 0.5297, 0.2906, 0.3178, 0.3148],\n",
      "        [0.1881, 0.5415, 0.2887, 0.3523, 0.3321],\n",
      "        [0.1678, 0.6068, 0.2598, 0.3728, 0.3042],\n",
      "        [0.1590, 0.5770, 0.2764, 0.3291, 0.2990],\n",
      "        [0.2142, 0.4979, 0.3715, 0.3885, 0.3297],\n",
      "        [0.1593, 0.5777, 0.2641, 0.3290, 0.2921],\n",
      "        [0.1785, 0.5686, 0.2906, 0.3473, 0.3255],\n",
      "        [0.1769, 0.5484, 0.2887, 0.3211, 0.3192],\n",
      "        [0.1716, 0.5370, 0.2815, 0.3294, 0.3129],\n",
      "        [0.1712, 0.5138, 0.2956, 0.3509, 0.3266],\n",
      "        [0.1841, 0.5503, 0.2986, 0.3228, 0.3173],\n",
      "        [0.1652, 0.5479, 0.2769, 0.3212, 0.3131],\n",
      "        [0.1647, 0.6145, 0.2619, 0.3437, 0.2830],\n",
      "        [0.1642, 0.5618, 0.2763, 0.3120, 0.3080],\n",
      "        [0.1876, 0.5290, 0.2982, 0.3423, 0.3311],\n",
      "        [0.1715, 0.5930, 0.2593, 0.3390, 0.2764],\n",
      "        [0.1678, 0.5977, 0.2689, 0.3443, 0.2888],\n",
      "        [0.1816, 0.5469, 0.3003, 0.3208, 0.3166],\n",
      "        [0.1575, 0.5850, 0.2715, 0.3389, 0.2852],\n",
      "        [0.1522, 0.5710, 0.2753, 0.3368, 0.2901],\n",
      "        [0.1815, 0.5559, 0.2766, 0.3323, 0.3551],\n",
      "        [0.1801, 0.5678, 0.2732, 0.3490, 0.3202],\n",
      "        [0.1772, 0.5573, 0.3004, 0.3661, 0.3352],\n",
      "        [0.1832, 0.5801, 0.2548, 0.3439, 0.3238],\n",
      "        [0.1879, 0.5323, 0.2985, 0.3137, 0.3294],\n",
      "        [0.1666, 0.5685, 0.2521, 0.3345, 0.3023],\n",
      "        [0.1655, 0.6091, 0.2594, 0.3558, 0.2735],\n",
      "        [0.1617, 0.5998, 0.2547, 0.3367, 0.3003],\n",
      "        [0.1794, 0.5558, 0.2694, 0.3195, 0.3529],\n",
      "        [0.1833, 0.5550, 0.2577, 0.3587, 0.3260],\n",
      "        [0.1835, 0.5428, 0.2767, 0.3403, 0.3554],\n",
      "        [0.2025, 0.5543, 0.3129, 0.3718, 0.3150],\n",
      "        [0.1654, 0.5671, 0.2459, 0.3310, 0.3142],\n",
      "        [0.1712, 0.6093, 0.2645, 0.3225, 0.2944],\n",
      "        [0.1741, 0.5750, 0.2627, 0.3116, 0.3112],\n",
      "        [0.2061, 0.5341, 0.2944, 0.3325, 0.3416],\n",
      "        [0.1785, 0.5694, 0.2922, 0.3606, 0.3076],\n",
      "        [0.2017, 0.5349, 0.2875, 0.3644, 0.3386],\n",
      "        [0.1953, 0.5527, 0.2945, 0.3729, 0.3427],\n",
      "        [0.1782, 0.6101, 0.2579, 0.3545, 0.2974]])\n",
      "EXP # =  6  THRESH =  0.35  MICRO F1 =  0.5203252032520326\n",
      "EXP # =  6  THRESH =  0.4  MICRO F1 =  0.431924882629108\n",
      "EXP # =  6  THRESH =  0.45  MICRO F1 =  0.431924882629108\n",
      "EXP # =  6  THRESH =  0.5  MICRO F1 =  0.4339622641509434\n",
      "EXP # =  6  THRESH =  0.55  MICRO F1 =  0.39572192513368987\n",
      "EXP # =  6  THRESH =  0.6  MICRO F1 =  0.14084507042253522\n",
      "EXP # =  6  THRESH =  0.65  MICRO F1 =  0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165fb4cfb53b41f7b966392729caf8eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBS:  tensor([[0.2855, 0.6082, 0.3372, 0.3545, 0.3671],\n",
      "        [0.2735, 0.6117, 0.3294, 0.3554, 0.3773],\n",
      "        [0.2949, 0.5666, 0.3461, 0.3465, 0.3957],\n",
      "        [0.2763, 0.5851, 0.3260, 0.3448, 0.3758],\n",
      "        [0.2999, 0.5836, 0.3448, 0.3865, 0.4057],\n",
      "        [0.2955, 0.5706, 0.3515, 0.3379, 0.4256],\n",
      "        [0.2713, 0.5903, 0.3352, 0.3410, 0.3905],\n",
      "        [0.2730, 0.5864, 0.3340, 0.3544, 0.3892],\n",
      "        [0.2835, 0.5776, 0.3525, 0.3710, 0.4057],\n",
      "        [0.2729, 0.5982, 0.3313, 0.3533, 0.3774],\n",
      "        [0.2857, 0.5845, 0.3482, 0.3701, 0.3967],\n",
      "        [0.2727, 0.6049, 0.3272, 0.3639, 0.3896],\n",
      "        [0.2980, 0.5779, 0.3468, 0.3588, 0.4278],\n",
      "        [0.2890, 0.5936, 0.3607, 0.3723, 0.4027],\n",
      "        [0.3044, 0.5738, 0.3663, 0.3784, 0.4201],\n",
      "        [0.2784, 0.5905, 0.3393, 0.3662, 0.3876],\n",
      "        [0.2676, 0.5878, 0.3249, 0.3554, 0.3816],\n",
      "        [0.2660, 0.6024, 0.3259, 0.3518, 0.3839],\n",
      "        [0.2950, 0.5664, 0.3758, 0.3489, 0.4083],\n",
      "        [0.2769, 0.5999, 0.3297, 0.3526, 0.3888],\n",
      "        [0.2645, 0.5891, 0.3501, 0.3624, 0.3828],\n",
      "        [0.2654, 0.5822, 0.3218, 0.3444, 0.3946],\n",
      "        [0.2736, 0.5913, 0.3402, 0.3590, 0.3936],\n",
      "        [0.2834, 0.5929, 0.3361, 0.3697, 0.3842],\n",
      "        [0.2898, 0.5646, 0.3624, 0.3478, 0.4237],\n",
      "        [0.2769, 0.5615, 0.3553, 0.3642, 0.3989],\n",
      "        [0.2735, 0.6015, 0.3321, 0.3706, 0.3942],\n",
      "        [0.2819, 0.5771, 0.3416, 0.3483, 0.4319],\n",
      "        [0.2612, 0.5953, 0.3236, 0.3417, 0.3737],\n",
      "        [0.2746, 0.5844, 0.3347, 0.3512, 0.3949],\n",
      "        [0.2976, 0.5510, 0.3371, 0.3668, 0.4421],\n",
      "        [0.2851, 0.6130, 0.3223, 0.3530, 0.3799],\n",
      "        [0.2797, 0.5760, 0.3459, 0.3366, 0.3750],\n",
      "        [0.2664, 0.5913, 0.3208, 0.3535, 0.3724],\n",
      "        [0.2781, 0.5972, 0.3369, 0.3378, 0.3748],\n",
      "        [0.2657, 0.6028, 0.3280, 0.3644, 0.3948],\n",
      "        [0.3044, 0.5705, 0.3433, 0.3705, 0.3950],\n",
      "        [0.2797, 0.5811, 0.3348, 0.3626, 0.3889],\n",
      "        [0.2907, 0.5725, 0.3721, 0.3696, 0.3979],\n",
      "        [0.2678, 0.5989, 0.3269, 0.3557, 0.3800],\n",
      "        [0.2971, 0.5874, 0.3488, 0.3389, 0.3724],\n",
      "        [0.2748, 0.5979, 0.3420, 0.3449, 0.3804],\n",
      "        [0.2954, 0.5828, 0.3462, 0.3529, 0.4119],\n",
      "        [0.2947, 0.5750, 0.3496, 0.3452, 0.3931],\n",
      "        [0.2973, 0.5738, 0.3440, 0.3632, 0.4184],\n",
      "        [0.2820, 0.6042, 0.3428, 0.3573, 0.3748],\n",
      "        [0.2720, 0.5901, 0.3316, 0.3501, 0.3641],\n",
      "        [0.3112, 0.5556, 0.3835, 0.3635, 0.4380],\n",
      "        [0.2792, 0.5889, 0.3240, 0.3444, 0.3734],\n",
      "        [0.2879, 0.5807, 0.3532, 0.3641, 0.4101],\n",
      "        [0.2875, 0.5924, 0.3367, 0.3507, 0.3895],\n",
      "        [0.2783, 0.5733, 0.3377, 0.3650, 0.4049],\n",
      "        [0.2941, 0.5740, 0.3500, 0.3430, 0.4218],\n",
      "        [0.2904, 0.5753, 0.3442, 0.3799, 0.4144],\n",
      "        [0.2651, 0.5548, 0.3402, 0.3517, 0.3996],\n",
      "        [0.2773, 0.6090, 0.3186, 0.3587, 0.3748],\n",
      "        [0.2877, 0.5884, 0.3374, 0.3446, 0.3638],\n",
      "        [0.2830, 0.5730, 0.3390, 0.3598, 0.4270],\n",
      "        [0.2794, 0.6002, 0.3238, 0.3453, 0.3767],\n",
      "        [0.2898, 0.6070, 0.3374, 0.3429, 0.3679],\n",
      "        [0.2985, 0.5837, 0.3559, 0.3490, 0.3862],\n",
      "        [0.2796, 0.5944, 0.3299, 0.3483, 0.3626],\n",
      "        [0.2560, 0.5793, 0.3493, 0.3441, 0.3839],\n",
      "        [0.2875, 0.5772, 0.3637, 0.3564, 0.4116],\n",
      "        [0.3029, 0.5644, 0.3311, 0.3473, 0.4045],\n",
      "        [0.2939, 0.5940, 0.3441, 0.3640, 0.4052],\n",
      "        [0.2824, 0.5919, 0.3323, 0.3641, 0.4036],\n",
      "        [0.2864, 0.5802, 0.3436, 0.3592, 0.4079],\n",
      "        [0.2653, 0.5897, 0.3374, 0.3482, 0.3909],\n",
      "        [0.2748, 0.6031, 0.3289, 0.3450, 0.3735],\n",
      "        [0.2733, 0.6064, 0.3374, 0.3495, 0.3772],\n",
      "        [0.2859, 0.5838, 0.3407, 0.3659, 0.4051],\n",
      "        [0.2804, 0.5893, 0.3357, 0.3558, 0.3968],\n",
      "        [0.2756, 0.5743, 0.3252, 0.3512, 0.4184],\n",
      "        [0.2793, 0.5833, 0.3484, 0.3696, 0.4125],\n",
      "        [0.2617, 0.5791, 0.3362, 0.3320, 0.3921],\n",
      "        [0.2732, 0.6082, 0.3340, 0.3634, 0.3725],\n",
      "        [0.2645, 0.5948, 0.3287, 0.3619, 0.4081],\n",
      "        [0.2998, 0.5423, 0.3439, 0.3558, 0.4452],\n",
      "        [0.2914, 0.5776, 0.3422, 0.3371, 0.4032],\n",
      "        [0.2803, 0.5826, 0.3547, 0.3516, 0.4039],\n",
      "        [0.3047, 0.5676, 0.3235, 0.3615, 0.4178],\n",
      "        [0.2790, 0.5985, 0.3308, 0.3668, 0.3860]])\n",
      "EXP # =  7  THRESH =  0.35  MICRO F1 =  0.5901639344262295\n",
      "EXP # =  7  THRESH =  0.4  MICRO F1 =  0.5163934426229508\n",
      "EXP # =  7  THRESH =  0.45  MICRO F1 =  0.431924882629108\n",
      "EXP # =  7  THRESH =  0.5  MICRO F1 =  0.431924882629108\n",
      "EXP # =  7  THRESH =  0.55  MICRO F1 =  0.4339622641509434\n",
      "EXP # =  7  THRESH =  0.6  MICRO F1 =  0.1388888888888889\n",
      "EXP # =  7  THRESH =  0.65  MICRO F1 =  0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1636b6392f7243c4acb5d5944981e3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBS:  tensor([[0.4053, 0.5936, 0.3996, 0.3829, 0.4327],\n",
      "        [0.3952, 0.5907, 0.3998, 0.3921, 0.4331],\n",
      "        [0.4151, 0.5498, 0.4205, 0.4005, 0.4521],\n",
      "        [0.3984, 0.5645, 0.4109, 0.3892, 0.4376],\n",
      "        [0.4105, 0.5648, 0.4199, 0.4202, 0.4483],\n",
      "        [0.3998, 0.5538, 0.4302, 0.3941, 0.4719],\n",
      "        [0.3920, 0.5684, 0.4150, 0.3990, 0.4634],\n",
      "        [0.3998, 0.5674, 0.4029, 0.3867, 0.4490],\n",
      "        [0.3899, 0.5618, 0.4290, 0.4072, 0.4457],\n",
      "        [0.3992, 0.5683, 0.4103, 0.3967, 0.4381],\n",
      "        [0.4011, 0.5520, 0.4263, 0.4128, 0.4587],\n",
      "        [0.3921, 0.5860, 0.3938, 0.3964, 0.4493],\n",
      "        [0.4086, 0.5567, 0.4197, 0.4145, 0.4781],\n",
      "        [0.4001, 0.5682, 0.4374, 0.4148, 0.4455],\n",
      "        [0.4166, 0.5523, 0.4338, 0.4336, 0.4658],\n",
      "        [0.3859, 0.5707, 0.4085, 0.4125, 0.4476],\n",
      "        [0.3823, 0.5756, 0.3857, 0.4001, 0.4402],\n",
      "        [0.3877, 0.5657, 0.4141, 0.4067, 0.4552],\n",
      "        [0.4039, 0.5500, 0.4428, 0.3957, 0.4637],\n",
      "        [0.3907, 0.5748, 0.4037, 0.3966, 0.4487],\n",
      "        [0.3836, 0.5765, 0.4153, 0.4021, 0.4493],\n",
      "        [0.3817, 0.5714, 0.4091, 0.3971, 0.4569],\n",
      "        [0.3907, 0.5665, 0.4135, 0.4067, 0.4604],\n",
      "        [0.4004, 0.5606, 0.4168, 0.4174, 0.4464],\n",
      "        [0.4067, 0.5565, 0.4383, 0.3979, 0.4817],\n",
      "        [0.3900, 0.5462, 0.4341, 0.4125, 0.4514],\n",
      "        [0.3799, 0.5812, 0.4063, 0.4147, 0.4555],\n",
      "        [0.3952, 0.5632, 0.4049, 0.3966, 0.4819],\n",
      "        [0.3833, 0.5670, 0.4049, 0.3867, 0.4395],\n",
      "        [0.3869, 0.5641, 0.3988, 0.3961, 0.4551],\n",
      "        [0.4019, 0.5305, 0.4046, 0.4179, 0.4828],\n",
      "        [0.4081, 0.5883, 0.3950, 0.3937, 0.4366],\n",
      "        [0.3928, 0.5609, 0.4202, 0.3834, 0.4439],\n",
      "        [0.3785, 0.5633, 0.3907, 0.3932, 0.4412],\n",
      "        [0.3973, 0.5703, 0.4206, 0.3818, 0.4429],\n",
      "        [0.3813, 0.5796, 0.4043, 0.4037, 0.4526],\n",
      "        [0.4191, 0.5502, 0.4177, 0.4236, 0.4491],\n",
      "        [0.3915, 0.5615, 0.4039, 0.3972, 0.4561],\n",
      "        [0.4089, 0.5475, 0.4419, 0.4185, 0.4541],\n",
      "        [0.3887, 0.5758, 0.4027, 0.3986, 0.4374],\n",
      "        [0.4158, 0.5656, 0.4199, 0.3826, 0.4335],\n",
      "        [0.3982, 0.5728, 0.4173, 0.3932, 0.4474],\n",
      "        [0.4043, 0.5601, 0.4196, 0.4014, 0.4702],\n",
      "        [0.4057, 0.5580, 0.4267, 0.3971, 0.4530],\n",
      "        [0.4092, 0.5510, 0.4215, 0.4056, 0.4675],\n",
      "        [0.3952, 0.5834, 0.4091, 0.3948, 0.4363],\n",
      "        [0.3880, 0.5685, 0.4016, 0.3930, 0.4233],\n",
      "        [0.4117, 0.5467, 0.4451, 0.4051, 0.4843],\n",
      "        [0.3993, 0.5632, 0.4010, 0.3934, 0.4358],\n",
      "        [0.3953, 0.5658, 0.4242, 0.4019, 0.4613],\n",
      "        [0.4122, 0.5697, 0.4096, 0.4050, 0.4471],\n",
      "        [0.3955, 0.5490, 0.4126, 0.4157, 0.4634],\n",
      "        [0.4097, 0.5638, 0.4216, 0.3893, 0.4662],\n",
      "        [0.4078, 0.5424, 0.4158, 0.4342, 0.4738],\n",
      "        [0.3749, 0.5458, 0.4147, 0.3963, 0.4623],\n",
      "        [0.3940, 0.5779, 0.3992, 0.4030, 0.4384],\n",
      "        [0.3977, 0.5694, 0.4081, 0.3934, 0.4304],\n",
      "        [0.3977, 0.5570, 0.4052, 0.4014, 0.4748],\n",
      "        [0.3988, 0.5760, 0.3859, 0.3822, 0.4435],\n",
      "        [0.4029, 0.5895, 0.4034, 0.3830, 0.4344],\n",
      "        [0.4100, 0.5589, 0.4269, 0.3985, 0.4486],\n",
      "        [0.3983, 0.5786, 0.3885, 0.3864, 0.4242],\n",
      "        [0.3764, 0.5523, 0.4305, 0.3925, 0.4498],\n",
      "        [0.4032, 0.5539, 0.4438, 0.4127, 0.4624],\n",
      "        [0.4283, 0.5480, 0.4039, 0.3963, 0.4643],\n",
      "        [0.4071, 0.5747, 0.4196, 0.4076, 0.4530],\n",
      "        [0.4047, 0.5753, 0.4038, 0.4118, 0.4624],\n",
      "        [0.4072, 0.5538, 0.4141, 0.4175, 0.4676],\n",
      "        [0.3805, 0.5652, 0.4186, 0.3974, 0.4526],\n",
      "        [0.3919, 0.5756, 0.4137, 0.3915, 0.4384],\n",
      "        [0.3997, 0.5772, 0.4127, 0.3879, 0.4348],\n",
      "        [0.4004, 0.5666, 0.4110, 0.4063, 0.4459],\n",
      "        [0.3976, 0.5742, 0.4259, 0.4033, 0.4547],\n",
      "        [0.3958, 0.5559, 0.4032, 0.3931, 0.4634],\n",
      "        [0.3944, 0.5628, 0.4225, 0.4144, 0.4721],\n",
      "        [0.3788, 0.5534, 0.4140, 0.3890, 0.4529],\n",
      "        [0.3862, 0.5882, 0.4019, 0.4011, 0.4392],\n",
      "        [0.3870, 0.5637, 0.4108, 0.4145, 0.4677],\n",
      "        [0.4101, 0.5195, 0.4145, 0.4099, 0.4885],\n",
      "        [0.4037, 0.5581, 0.4098, 0.3754, 0.4602],\n",
      "        [0.4059, 0.5612, 0.4267, 0.3982, 0.4634],\n",
      "        [0.4129, 0.5536, 0.3951, 0.4089, 0.4667],\n",
      "        [0.3958, 0.5737, 0.4098, 0.4152, 0.4448]])\n",
      "EXP # =  8  THRESH =  0.35  MICRO F1 =  0.47706422018348627\n",
      "EXP # =  8  THRESH =  0.4  MICRO F1 =  0.497737556561086\n",
      "EXP # =  8  THRESH =  0.45  MICRO F1 =  0.5058365758754864\n",
      "EXP # =  8  THRESH =  0.5  MICRO F1 =  0.431924882629108\n",
      "EXP # =  8  THRESH =  0.55  MICRO F1 =  0.43564356435643564\n",
      "EXP # =  8  THRESH =  0.6  MICRO F1 =  0.0\n",
      "EXP # =  8  THRESH =  0.65  MICRO F1 =  0.0\n",
      "7\n",
      "0.5901639344262295\n",
      "0.35\n"
     ]
    }
   ],
   "source": [
    "# evaluate performance\n",
    "best_model_num = 0\n",
    "best_micro_f1 = 0\n",
    "corresponding_thresh = 0\n",
    "\n",
    "for curr_experiment in [6, 7, 8]:\n",
    "  predictions = experiments[curr_experiment][\"trainer\"].predict(mini_tokenized_test) # logits\n",
    "  probs = torch.sigmoid(torch.from_numpy(predictions.predictions)) # percentage probabilities\n",
    "  # probs_array = probs.numpy()\n",
    "  # formatted_probs = np.array([[f\"{value:.3f}\" for value in row] for row in probs_array])\n",
    "\n",
    "  print(\"PROBS: \", probs)\n",
    "  # print(\"LABELS: \", torch.tensor(mini_tokenized_test['label'])) # trues\n",
    "  \n",
    "  best_thresh = 0\n",
    "  best_f1_thresh = 0\n",
    "  for thresh in [0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65]:\n",
    "    # binarize predictions\n",
    "    binary_predictions = (probs >= thresh).long()\n",
    "    # print(\"THRESH = \", thresh)\n",
    "\n",
    "    # get F1 scores\n",
    "    curr_f1 = f1_score(y_true=mini_tokenized_test['label'], y_pred=binary_predictions, average='micro')\n",
    "    print(\"EXP # = \", curr_experiment, \" THRESH = \", thresh, \" MICRO F1 = \", curr_f1)\n",
    "    if curr_f1 > best_f1_thresh:\n",
    "      best_thresh = thresh\n",
    "      best_f1_thresh = curr_f1\n",
    "  \n",
    "  if best_f1_thresh > best_micro_f1:\n",
    "    best_model_num = curr_experiment\n",
    "    best_micro_f1 = best_f1_thresh\n",
    "    corresponding_thresh = best_thresh\n",
    "\n",
    "print(best_model_num)\n",
    "print(best_micro_f1)\n",
    "print(corresponding_thresh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sem-eval-11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
