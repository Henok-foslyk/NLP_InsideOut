{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Evaluating Binary Relevance with Logistic Regression...\n",
      "\n",
      "\n",
      "EVALUATION: Binary Relevance with Logistic Regression\n",
      "MICRO recall: 0.4272, precision: 0.6364, f1: 0.5112\n",
      "MACRO recall: 0.298, precision: 0.4758, f1: 0.3388\n",
      "\n",
      "PER CLASS BREAKDOWN\n",
      "*** Anger ***\n",
      "recall: 0.0, precision: 0.0, f1: 0.0\n",
      "\n",
      "*** Fear ***\n",
      "recall: 0.7375, precision: 0.6782, f1: 0.7066\n",
      "\n",
      "*** Joy ***\n",
      "recall: 0.1034, precision: 0.5, f1: 0.1714\n",
      "\n",
      "*** Sadness ***\n",
      "recall: 0.2174, precision: 0.625, f1: 0.3226\n",
      "\n",
      "*** Surprise ***\n",
      "recall: 0.4318, precision: 0.5758, f1: 0.4935\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Classifier Chain with Logistic Regression...\n",
      "\n",
      "\n",
      "EVALUATION: Classifier Chain with Logistic Regression\n",
      "MICRO recall: 0.4836, precision: 0.6023, f1: 0.5365\n",
      "MACRO recall: 0.39, precision: 0.4644, f1: 0.4171\n",
      "\n",
      "PER CLASS BREAKDOWN\n",
      "*** Anger ***\n",
      "recall: 0.0, precision: 0.0, f1: 0.0\n",
      "\n",
      "*** Fear ***\n",
      "recall: 0.675, precision: 0.6835, f1: 0.6792\n",
      "\n",
      "*** Joy ***\n",
      "recall: 0.5172, precision: 0.5, f1: 0.5085\n",
      "\n",
      "*** Sadness ***\n",
      "recall: 0.3261, precision: 0.625, f1: 0.4286\n",
      "\n",
      "*** Surprise ***\n",
      "recall: 0.4318, precision: 0.5135, f1: 0.4691\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Binary Relevance with Random Forest...\n",
      "\n",
      "\n",
      "EVALUATION: Binary Relevance with Random Forest\n",
      "MICRO recall: 0.4178, precision: 0.6357, f1: 0.5042\n",
      "MACRO recall: 0.2543, precision: 0.8825, f1: 0.2559\n",
      "\n",
      "PER CLASS BREAKDOWN\n",
      "*** Anger ***\n",
      "recall: 0.0714, precision: 1.0, f1: 0.1333\n",
      "\n",
      "*** Fear ***\n",
      "recall: 0.9875, precision: 0.6124, f1: 0.756\n",
      "\n",
      "*** Joy ***\n",
      "recall: 0.0345, precision: 1.0, f1: 0.0667\n",
      "\n",
      "*** Sadness ***\n",
      "recall: 0.087, precision: 0.8, f1: 0.1569\n",
      "\n",
      "*** Surprise ***\n",
      "recall: 0.0909, precision: 1.0, f1: 0.1667\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Classifier Chain with Random Forest...\n",
      "\n",
      "\n",
      "EVALUATION: Classifier Chain with Random Forest\n",
      "MICRO recall: 0.4319, precision: 0.6571, f1: 0.5212\n",
      "MACRO recall: 0.26, precision: 0.6307, f1: 0.2648\n",
      "\n",
      "PER CLASS BREAKDOWN\n",
      "*** Anger ***\n",
      "recall: 0.0, precision: 0.0, f1: 0.0\n",
      "\n",
      "*** Fear ***\n",
      "recall: 0.975, precision: 0.6393, f1: 0.7723\n",
      "\n",
      "*** Joy ***\n",
      "recall: 0.0345, precision: 1.0, f1: 0.0667\n",
      "\n",
      "*** Sadness ***\n",
      "recall: 0.1087, precision: 0.7143, f1: 0.1887\n",
      "\n",
      "*** Surprise ***\n",
      "recall: 0.1818, precision: 0.8, f1: 0.2963\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Binary Relevance with SVM...\n",
      "\n",
      "\n",
      "EVALUATION: Binary Relevance with SVM\n",
      "MICRO recall: 0.4648, precision: 0.6266, f1: 0.5337\n",
      "MACRO recall: 0.3633, precision: 0.5279, f1: 0.4179\n",
      "\n",
      "PER CLASS BREAKDOWN\n",
      "*** Anger ***\n",
      "recall: 0.0714, precision: 0.25, f1: 0.1111\n",
      "\n",
      "*** Fear ***\n",
      "recall: 0.6875, precision: 0.7051, f1: 0.6962\n",
      "\n",
      "*** Joy ***\n",
      "recall: 0.2759, precision: 0.5333, f1: 0.3636\n",
      "\n",
      "*** Sadness ***\n",
      "recall: 0.3043, precision: 0.5833, f1: 0.4\n",
      "\n",
      "*** Surprise ***\n",
      "recall: 0.4773, precision: 0.5676, f1: 0.5185\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Classifier Chain with SVM...\n",
      "\n",
      "\n",
      "EVALUATION: Classifier Chain with SVM\n",
      "MICRO recall: 0.4977, precision: 0.5989, f1: 0.5436\n",
      "MACRO recall: 0.4111, precision: 0.5037, f1: 0.442\n",
      "\n",
      "PER CLASS BREAKDOWN\n",
      "*** Anger ***\n",
      "recall: 0.0714, precision: 0.25, f1: 0.1111\n",
      "\n",
      "*** Fear ***\n",
      "recall: 0.675, precision: 0.7297, f1: 0.7013\n",
      "\n",
      "*** Joy ***\n",
      "recall: 0.4828, precision: 0.4667, f1: 0.4746\n",
      "\n",
      "*** Sadness ***\n",
      "recall: 0.3261, precision: 0.5357, f1: 0.4054\n",
      "\n",
      "*** Surprise ***\n",
      "recall: 0.5, precision: 0.5366, f1: 0.5176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from skmultilearn.problem_transform import ClassifierChain, BinaryRelevance\n",
    "\n",
    "\n",
    "# Assuming you have your dataset as a DataFrame, with 'text' as the feature column and emotions as the labels\n",
    "emotions = ['Anger', 'Fear', 'Joy', 'Sadness', 'Surprise']\n",
    "\n",
    "# Read your data (replace with your actual dataset)\n",
    "train = pd.read_csv('eng_train.csv')\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train, val = train_test_split(train, test_size=0.05, random_state=42)\n",
    "\n",
    "# Vectorize the text data using CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "X_train = vectorizer.fit_transform(train['text'].str.lower()).toarray()\n",
    "X_val = vectorizer.transform(val['text'].str.lower()).toarray()\n",
    "\n",
    "# Prepare the labels\n",
    "y_train = train[emotions].values\n",
    "y_val = val[emotions].values\n",
    "\n",
    "# Function to evaluate performance of models\n",
    "def evaluate(y_val, y_pred):\n",
    "    for average in ['micro', 'macro']:\n",
    "        recall = recall_score(y_val, y_pred, average=average, zero_division=0)\n",
    "        precision = precision_score(y_val, y_pred, average=average, zero_division=0)\n",
    "        f1 = f1_score(y_val, y_pred, average=average, zero_division=0)\n",
    "    \n",
    "        print(f'{average.upper()} recall: {round(recall, 4)}, precision: {round(precision, 4)}, f1: {round(f1, 4)}')\n",
    "\n",
    "# Function to evaluate per class\n",
    "def evaluate_per_class(y_val, y_pred):\n",
    "    y_val_dense = y_val.toarray() if hasattr(y_val, 'toarray') else y_val  # Convert sparse to dense if needed\n",
    "    y_pred_dense = y_pred.toarray() if hasattr(y_pred, 'toarray') else y_pred  # Convert sparse to dense if needed\n",
    "\n",
    "    for i, emotion in enumerate(emotions):\n",
    "        print(f'*** {emotion} ***')\n",
    "    \n",
    "        recall = recall_score(y_val_dense[:,i], y_pred_dense[:,i], zero_division=0)\n",
    "        precision = precision_score(y_val_dense[:,i], y_pred_dense[:,i], zero_division=0)\n",
    "        f1 = f1_score(y_val_dense[:,i], y_pred_dense[:,i], zero_division=0)\n",
    "        \n",
    "        print(f'recall: {round(recall, 4)}, precision: {round(precision, 4)}, f1: {round(f1, 4)}\\n')\n",
    "\n",
    "# Define models to evaluate\n",
    "models = {\n",
    "    'Binary Relevance with Logistic Regression': BinaryRelevance(LogisticRegression(max_iter=1000)),\n",
    "    'Classifier Chain with Logistic Regression': ClassifierChain(LogisticRegression(max_iter=1000)),\n",
    "    'Binary Relevance with Random Forest': BinaryRelevance(RandomForestClassifier(n_estimators=100)),\n",
    "    'Classifier Chain with Random Forest': ClassifierChain(RandomForestClassifier(n_estimators=100)),\n",
    "    'Binary Relevance with SVM': BinaryRelevance(SVC(kernel='linear', probability=True)),\n",
    "    'Classifier Chain with SVM': ClassifierChain(SVC(kernel='linear', probability=True))\n",
    "}\n",
    "\n",
    "# Evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    print(f'\\n\\nEvaluating {model_name}...\\n')\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Evaluate model performance\n",
    "    print(f'\\nEVALUATION: {model_name}')\n",
    "    evaluate(y_val, y_pred)\n",
    "    \n",
    "    print('\\nPER CLASS BREAKDOWN')\n",
    "    evaluate_per_class(y_val, y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
